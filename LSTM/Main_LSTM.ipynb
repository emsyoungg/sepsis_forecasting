{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-06T11:50:57.741160300Z",
     "start_time": "2025-04-06T11:50:52.848251200Z"
    }
   },
   "outputs": [],
   "source": [
    "import loadDataForSKtime\n",
    "import LSTMmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Patient 1: Dropping — constant columns found\n",
      "Patient 2: Less than 50 time points — skipping.\n",
      "Patient 3: Less than 50 time points — skipping.\n",
      "Patient 4: Less than 50 time points — skipping.\n",
      "Patient 5: Less than 50 time points — skipping.\n",
      "Patient 6: Less than 50 time points — skipping.\n",
      "Patient 7: Less than 50 time points — skipping.\n",
      "Patient 8: Less than 50 time points — skipping.\n",
      "Patient 10: Less than 50 time points — skipping.\n",
      "Patient 11: Less than 50 time points — skipping.\n",
      "Patient 12: Less than 50 time points — skipping.\n",
      "Patient 13: Less than 50 time points — skipping.\n",
      "Patient 14: Less than 50 time points — skipping.\n",
      "Patient 15: Less than 50 time points — skipping.\n",
      "Patient 16: Less than 50 time points — skipping.\n",
      "Patient 17: Less than 50 time points — skipping.\n",
      "Patient 19: Less than 50 time points — skipping.\n",
      "Patient 20: Less than 50 time points — skipping.\n",
      "Patient 22: Less than 50 time points — skipping.\n",
      "Patient 23: Less than 50 time points — skipping.\n",
      "Patient 24: Dropping — constant columns found\n",
      "Patient 25: Dropping — constant columns found\n",
      "Patient 26: Less than 50 time points — skipping.\n",
      "Patient 27: Less than 50 time points — skipping.\n",
      "Patient 28: Less than 50 time points — skipping.\n",
      "Patient 29: Less than 50 time points — skipping.\n",
      "Patient 30: Less than 50 time points — skipping.\n",
      "Patient 32: Dropping — constant columns found\n",
      "Patient 33: Less than 50 time points — skipping.\n",
      "Patient 34: Less than 50 time points — skipping.\n",
      "Patient 35: Less than 50 time points — skipping.\n",
      "Patient 36: Less than 50 time points — skipping.\n",
      "Patient 37: Less than 50 time points — skipping.\n",
      "Patient 38: Less than 50 time points — skipping.\n",
      "Patient 39: Less than 50 time points — skipping.\n",
      "Patient 40: Less than 50 time points — skipping.\n",
      "Patient 41: Less than 50 time points — skipping.\n",
      "Patient 43: Less than 50 time points — skipping.\n",
      "Patient 44: Less than 50 time points — skipping.\n",
      "Patient 45: Less than 50 time points — skipping.\n",
      "Patient 47: Less than 50 time points — skipping.\n",
      "Patient 48: Less than 50 time points — skipping.\n",
      "Patient 49: Less than 50 time points — skipping.\n",
      "Patient 50: Dropping — constant columns found\n",
      "Patient 51: Less than 50 time points — skipping.\n",
      "Patient 52: Less than 50 time points — skipping.\n",
      "Patient 53: Less than 50 time points — skipping.\n",
      "Patient 55: Less than 50 time points — skipping.\n",
      "Patient 56: Less than 50 time points — skipping.\n",
      "Patient 57: Less than 50 time points — skipping.\n",
      "Patient 58: Less than 50 time points — skipping.\n",
      "Patient 59: Less than 50 time points — skipping.\n",
      "Patient 60: Less than 50 time points — skipping.\n",
      "Patient 61: Less than 50 time points — skipping.\n",
      "Patient 62: Less than 50 time points — skipping.\n",
      "Patient 63: Less than 50 time points — skipping.\n",
      "Patient 64: Less than 50 time points — skipping.\n",
      "Patient 65: Less than 50 time points — skipping.\n",
      "Patient 66: Less than 50 time points — skipping.\n",
      "Patient 67: Less than 50 time points — skipping.\n",
      "Patient 68: Less than 50 time points — skipping.\n",
      "Patient 69: Less than 50 time points — skipping.\n",
      "Patient 70: Less than 50 time points — skipping.\n",
      "Patient 72: Less than 50 time points — skipping.\n",
      "Patient 73: Less than 50 time points — skipping.\n",
      "Patient 74: Less than 50 time points — skipping.\n",
      "Patient 75: Less than 50 time points — skipping.\n",
      "Patient 77: Less than 50 time points — skipping.\n",
      "Patient 79: Less than 50 time points — skipping.\n",
      "Patient 80: Less than 50 time points — skipping.\n",
      "Patient 81: Less than 50 time points — skipping.\n",
      "Patient 82: Less than 50 time points — skipping.\n",
      "Patient 84: Less than 50 time points — skipping.\n",
      "Patient 85: Dropping — constant columns found\n",
      "Patient 86: Less than 50 time points — skipping.\n",
      "Patient 87: Less than 50 time points — skipping.\n",
      "Patient 88: Less than 50 time points — skipping.\n",
      "Patient 89: Less than 50 time points — skipping.\n",
      "Patient 90: Less than 50 time points — skipping.\n",
      "Patient 92: Less than 50 time points — skipping.\n",
      "Patient 93: Less than 50 time points — skipping.\n",
      "Patient 94: Less than 50 time points — skipping.\n",
      "Patient 95: Less than 50 time points — skipping.\n",
      "Patient 96: Less than 50 time points — skipping.\n",
      "Patient 97: Less than 50 time points — skipping.\n",
      "Patient 98: Dropping — constant columns found\n",
      "Patient 99: Less than 50 time points — skipping.\n",
      "Patient 100: Less than 50 time points — skipping.\n",
      "Patient 1: Dropping — constant columns found\n",
      "Patient 9: Dropping — constant columns found\n"
     ]
    }
   ],
   "source": [
    "loader = loadDataForSKtime.PatientTimeSeriesLoader(\n",
    "    \"C:/Users/emily/Documents/DissertationProject/training/training_setA_csv\", ['HR', 'O2Sat', 'SBP', 'MAP', 'DBP', 'Resp', 'Temp'])\n",
    "df = loader.load_data_LSTM(100)\n",
    "train_data, test_data = loader.split_train_test_LSTM(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-04T13:07:03.549955200Z",
     "start_time": "2025-04-04T13:07:01.585704300Z"
    }
   },
   "id": "aeffc725bcbf08d3"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                      HR  O2Sat    SBP    MAP   DBP  Resp   Temp\nPatient_ID ICULOS                                               \n0          0       117.0   99.0  116.0  97.00  81.0  20.0  36.00\n           1       117.0   99.0  116.0  97.00  81.0  20.0  36.00\n           2       117.0   99.0  116.0  97.00  81.0  20.0  36.00\n           3       117.0   99.0  116.0  97.00  81.0  20.0  36.00\n           4       117.0   99.0  116.0  97.00  81.0  20.0  36.00\n...                  ...    ...    ...    ...   ...   ...    ...\n9          39      117.0   95.0  125.0  71.67  65.0  24.5  37.39\n           40      106.0   95.0  116.0  66.00  47.0  23.0  37.67\n           41      113.0   97.0  102.0  72.00  55.0  22.0  37.67\n           42       98.0   98.0  108.5  68.00  53.0  19.0  37.67\n           43       95.0   97.0  111.0  65.00  48.0  20.0  37.67\n\n[440 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>HR</th>\n      <th>O2Sat</th>\n      <th>SBP</th>\n      <th>MAP</th>\n      <th>DBP</th>\n      <th>Resp</th>\n      <th>Temp</th>\n    </tr>\n    <tr>\n      <th>Patient_ID</th>\n      <th>ICULOS</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">0</th>\n      <th>0</th>\n      <td>117.0</td>\n      <td>99.0</td>\n      <td>116.0</td>\n      <td>97.00</td>\n      <td>81.0</td>\n      <td>20.0</td>\n      <td>36.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>117.0</td>\n      <td>99.0</td>\n      <td>116.0</td>\n      <td>97.00</td>\n      <td>81.0</td>\n      <td>20.0</td>\n      <td>36.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>117.0</td>\n      <td>99.0</td>\n      <td>116.0</td>\n      <td>97.00</td>\n      <td>81.0</td>\n      <td>20.0</td>\n      <td>36.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>117.0</td>\n      <td>99.0</td>\n      <td>116.0</td>\n      <td>97.00</td>\n      <td>81.0</td>\n      <td>20.0</td>\n      <td>36.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>117.0</td>\n      <td>99.0</td>\n      <td>116.0</td>\n      <td>97.00</td>\n      <td>81.0</td>\n      <td>20.0</td>\n      <td>36.00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">9</th>\n      <th>39</th>\n      <td>117.0</td>\n      <td>95.0</td>\n      <td>125.0</td>\n      <td>71.67</td>\n      <td>65.0</td>\n      <td>24.5</td>\n      <td>37.39</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>106.0</td>\n      <td>95.0</td>\n      <td>116.0</td>\n      <td>66.00</td>\n      <td>47.0</td>\n      <td>23.0</td>\n      <td>37.67</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>113.0</td>\n      <td>97.0</td>\n      <td>102.0</td>\n      <td>72.00</td>\n      <td>55.0</td>\n      <td>22.0</td>\n      <td>37.67</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>98.0</td>\n      <td>98.0</td>\n      <td>108.5</td>\n      <td>68.00</td>\n      <td>53.0</td>\n      <td>19.0</td>\n      <td>37.67</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>95.0</td>\n      <td>97.0</td>\n      <td>111.0</td>\n      <td>65.00</td>\n      <td>48.0</td>\n      <td>20.0</td>\n      <td>37.67</td>\n    </tr>\n  </tbody>\n</table>\n<p>440 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-04T13:07:10.581187600Z",
     "start_time": "2025-04-04T13:07:10.520444Z"
    }
   },
   "id": "203a1db0da610a6d"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import pickle\n",
    "train_data.to_pickle(\"train_data_small.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-02T15:41:11.129572700Z",
     "start_time": "2025-04-02T15:41:11.077777800Z"
    }
   },
   "id": "ef219eaa891b9d0c"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_pickle(\"train_data_small.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-02T14:04:43.671236800Z",
     "start_time": "2025-04-02T14:04:43.651980800Z"
    }
   },
   "id": "4fac8a1f3ad5bbcb"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train IDs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136]\n",
      "Test  IDs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train IDs:\", sorted(train_data.index.get_level_values(\"Patient_ID\").unique()))\n",
    "print(\"Test  IDs:\", sorted(test_data.index.get_level_values(\"Patient_ID\").unique()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-02T15:13:51.032535900Z",
     "start_time": "2025-04-02T15:13:50.982345Z"
    }
   },
   "id": "a42026dd9f1e1016"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sktime.datatypes import mtype\n",
    "import sktime.datatypes\n",
    "sktime.datatypes.check_raise(train_data, \"pd-multiindex\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-03T16:51:38.281137500Z",
     "start_time": "2025-04-03T16:51:38.158439900Z"
    }
   },
   "id": "9857a7c8f0289855"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "LSTMforecaster = LSTMmodel.LSTMforecaster(train_data, test_data, ['HR', 'O2Sat', 'SBP', 'MAP', 'DBP', 'Resp', 'Temp'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-04T13:09:18.324277200Z",
     "start_time": "2025-04-04T13:09:18.295091100Z"
    }
   },
   "id": "d161647e845e7926"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LSTMforecaster.fit_predict()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89fe33881449579b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://www.sktime.net/en/stable/api_reference/auto_generated/sktime.datatypes._panel._check.PanelPdMultiIndex.html#sktime.datatypes._panel._check.PanelPdMultiIndex"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b578886c0e5532df"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:138: UserWarning: Input size too small. Automatically setting input size to 3 * horizon = 138\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:146: UserWarning: Inference input size too small. Automatically setting inference input size to input_size = 138\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\models\\lstm.py:161: UserWarning: context_size is deprecated and will be removed in future versions.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:535: UserWarning: val_check_steps is greater than max_steps, setting val_check_steps to max_steps.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder | LSTM          | 484 K  | train\n",
      "4 | mlp_decoder  | MLP           | 40.4 K | train\n",
      "-------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "0         Non-trainable params\n",
      "524 K     Total params\n",
      "2.098     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb9df97369bf4444a18dac47ccfa77dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d19cbe2123c4d87b19bbaf47719dbcf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "121b485369cb439d87736672bfa1b290"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=10` reached.\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:138: UserWarning: Input size too small. Automatically setting input size to 3 * horizon = 138\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:146: UserWarning: Inference input size too small. Automatically setting inference input size to input_size = 138\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\models\\lstm.py:161: UserWarning: context_size is deprecated and will be removed in future versions.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:535: UserWarning: val_check_steps is greater than max_steps, setting val_check_steps to max_steps.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder | LSTM          | 484 K  | train\n",
      "4 | mlp_decoder  | MLP           | 40.4 K | train\n",
      "-------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "0         Non-trainable params\n",
      "524 K     Total params\n",
      "2.098     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06a1b4005b5941d6abbe81b9ceb2c27d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3a1c5546c14477cbcad6dca9b3bb177"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5f3b1ad210642c6aa1d3ca7fc160402"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=10` reached.\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:138: UserWarning: Input size too small. Automatically setting input size to 3 * horizon = 138\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:146: UserWarning: Inference input size too small. Automatically setting inference input size to input_size = 138\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\models\\lstm.py:161: UserWarning: context_size is deprecated and will be removed in future versions.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:535: UserWarning: val_check_steps is greater than max_steps, setting val_check_steps to max_steps.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder | LSTM          | 484 K  | train\n",
      "4 | mlp_decoder  | MLP           | 40.4 K | train\n",
      "-------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "0         Non-trainable params\n",
      "524 K     Total params\n",
      "2.098     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f68b7852971a4cd7a434b885c9a705c3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71b85308be084a2cac19b5d8291d1f58"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "364e90779e454db087ae7de969f9b971"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=10` reached.\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:138: UserWarning: Input size too small. Automatically setting input size to 3 * horizon = 138\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:146: UserWarning: Inference input size too small. Automatically setting inference input size to input_size = 138\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\models\\lstm.py:161: UserWarning: context_size is deprecated and will be removed in future versions.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:535: UserWarning: val_check_steps is greater than max_steps, setting val_check_steps to max_steps.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder | LSTM          | 484 K  | train\n",
      "4 | mlp_decoder  | MLP           | 40.4 K | train\n",
      "-------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "0         Non-trainable params\n",
      "524 K     Total params\n",
      "2.098     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e4a85d7d05c46fa92de8537c20e413c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ddd84983fc114c1088cd2da1f0d5a881"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a8db773008a649e5a6b6a12b63e81608"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=10` reached.\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:138: UserWarning: Input size too small. Automatically setting input size to 3 * horizon = 138\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:146: UserWarning: Inference input size too small. Automatically setting inference input size to input_size = 138\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\models\\lstm.py:161: UserWarning: context_size is deprecated and will be removed in future versions.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:535: UserWarning: val_check_steps is greater than max_steps, setting val_check_steps to max_steps.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder | LSTM          | 484 K  | train\n",
      "4 | mlp_decoder  | MLP           | 40.4 K | train\n",
      "-------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "0         Non-trainable params\n",
      "524 K     Total params\n",
      "2.098     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e354ac37bdbc4045be9759281761e44b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4cb5857545884624bc42066cbe3ea94b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d5afb569f1c34ef4a76a539de405d884"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=10` reached.\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:138: UserWarning: Input size too small. Automatically setting input size to 3 * horizon = 138\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:146: UserWarning: Inference input size too small. Automatically setting inference input size to input_size = 138\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\models\\lstm.py:161: UserWarning: context_size is deprecated and will be removed in future versions.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:535: UserWarning: val_check_steps is greater than max_steps, setting val_check_steps to max_steps.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder | LSTM          | 484 K  | train\n",
      "4 | mlp_decoder  | MLP           | 40.4 K | train\n",
      "-------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "0         Non-trainable params\n",
      "524 K     Total params\n",
      "2.098     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "18e6b9cb276d4670ab9eee0a8b80c66d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23910ed6bbe547cfa2268b79be52d159"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0062c2f014704e408f3f58ddbfb7b026"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=10` reached.\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:138: UserWarning: Input size too small. Automatically setting input size to 3 * horizon = 138\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:146: UserWarning: Inference input size too small. Automatically setting inference input size to input_size = 138\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\models\\lstm.py:161: UserWarning: context_size is deprecated and will be removed in future versions.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:535: UserWarning: val_check_steps is greater than max_steps, setting val_check_steps to max_steps.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder | LSTM          | 484 K  | train\n",
      "4 | mlp_decoder  | MLP           | 40.4 K | train\n",
      "-------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "0         Non-trainable params\n",
      "524 K     Total params\n",
      "2.098     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71cab6d580a04be1a232cad32763722c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a386af265ef3486094711b9a886011af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eba91c62c7bf4455b3db1bcc07e8396c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=10` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is fitted. Generating forecasts...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Predicting: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8ef79bce37c42e3b0e5ec136f0f9b20"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m LSTMforecaster \u001B[38;5;241m=\u001B[39m LSTMmodel\u001B[38;5;241m.\u001B[39mLSTMforecaster(train_data, test_data, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHR\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mO2Sat\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSBP\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMAP\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDBP\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mResp\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTemp\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m      2\u001B[0m LSTMforecaster\u001B[38;5;241m.\u001B[39mfit()\n\u001B[1;32m----> 3\u001B[0m LSTMforecasts \u001B[38;5;241m=\u001B[39m \u001B[43mLSTMforecaster\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\LSTMmodel.py:36\u001B[0m, in \u001B[0;36mLSTMforecaster.predict\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     31\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel is fitted. Generating forecasts...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     32\u001B[0m \u001B[38;5;66;03m# fh = ForecastingHorizon([44, 45, 46, 47, 48, 49], is_relative=False)\u001B[39;00m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;66;03m# print(\"Internal fh:\", self.forecaster._fh)\u001B[39;00m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;66;03m# print(\"Forecaster cutoff:\", self.forecaster.cutoff)\u001B[39;00m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;66;03m# print(\"ForecastingHorizon:\", fh)\u001B[39;00m\n\u001B[1;32m---> 36\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforecaster\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\forecasting\\base\\_base.py:2490\u001B[0m, in \u001B[0;36m_BaseGlobalForecaster.predict\u001B[1;34m(self, fh, X, y)\u001B[0m\n\u001B[0;32m   2487\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_predict(fh\u001B[38;5;241m=\u001B[39mfh, X\u001B[38;5;241m=\u001B[39mX_inner, y\u001B[38;5;241m=\u001B[39my_inner)\n\u001B[0;32m   2488\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2489\u001B[0m     \u001B[38;5;66;03m# otherwise we call the vectorized version of predict\u001B[39;00m\n\u001B[1;32m-> 2490\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_vectorize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpredict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_inner\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_inner\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfh\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfh\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2492\u001B[0m \u001B[38;5;66;03m# convert to output mtype, identical with last y mtype seen\u001B[39;00m\n\u001B[0;32m   2493\u001B[0m y_out \u001B[38;5;241m=\u001B[39m convert_to(\n\u001B[0;32m   2494\u001B[0m     y_pred,\n\u001B[0;32m   2495\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_y_metadata[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmtype\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   2496\u001B[0m     store\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_converter_store_y,\n\u001B[0;32m   2497\u001B[0m     store_behaviour\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfreeze\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   2498\u001B[0m )\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\forecasting\\base\\_base.py:2058\u001B[0m, in \u001B[0;36mBaseForecaster._vectorize\u001B[1;34m(self, methodname, **kwargs)\u001B[0m\n\u001B[0;32m   2055\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m methodname \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mupdate_predict_single\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   2056\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_yvec \u001B[38;5;241m=\u001B[39m y\n\u001B[1;32m-> 2058\u001B[0m y_preds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_yvec\u001B[38;5;241m.\u001B[39mvectorize_est(\n\u001B[0;32m   2059\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforecasters_,\n\u001B[0;32m   2060\u001B[0m     method\u001B[38;5;241m=\u001B[39mmethodname,\n\u001B[0;32m   2061\u001B[0m     return_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlist\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   2062\u001B[0m     backend\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_config()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbackend:parallel\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   2063\u001B[0m     backend_params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_config()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbackend:parallel:params\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   2064\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   2065\u001B[0m )\n\u001B[0;32m   2067\u001B[0m \u001B[38;5;66;03m# if we vectorize over columns,\u001B[39;00m\n\u001B[0;32m   2068\u001B[0m \u001B[38;5;66;03m#   we need to replace top column level with variable names - part 1\u001B[39;00m\n\u001B[0;32m   2069\u001B[0m m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforecasters_\u001B[38;5;241m.\u001B[39mcolumns)\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:630\u001B[0m, in \u001B[0;36mVectorizedDF.vectorize_est\u001B[1;34m(self, estimator, method, args, args_rowvec, return_type, rowname_default, colname_default, varname_of_self, backend, backend_params, **kwargs)\u001B[0m\n\u001B[0;32m    616\u001B[0m vec_zip \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\n\u001B[0;32m    617\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems(),\n\u001B[0;32m    618\u001B[0m     explode(args, iterate_as\u001B[38;5;241m=\u001B[39miterate_as, iterate_cols\u001B[38;5;241m=\u001B[39miterate_cols),\n\u001B[0;32m    619\u001B[0m     explode(args_rowvec, iterate_as\u001B[38;5;241m=\u001B[39miterate_as, iterate_cols\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[0;32m    620\u001B[0m     estimators,\n\u001B[0;32m    621\u001B[0m )\n\u001B[0;32m    623\u001B[0m meta \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    624\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmethod\u001B[39m\u001B[38;5;124m\"\u001B[39m: method,\n\u001B[0;32m    625\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvarname_of_self\u001B[39m\u001B[38;5;124m\"\u001B[39m: varname_of_self,\n\u001B[0;32m    626\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrowname_default\u001B[39m\u001B[38;5;124m\"\u001B[39m: rowname_default,\n\u001B[0;32m    627\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolname_default\u001B[39m\u001B[38;5;124m\"\u001B[39m: colname_default,\n\u001B[0;32m    628\u001B[0m }\n\u001B[1;32m--> 630\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[43mparallelize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    631\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfun\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_vectorize_est_single\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    632\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvec_zip\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    633\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmeta\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    634\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbackend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbackend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    635\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbackend_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbackend_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    636\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    638\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpd.DataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    639\u001B[0m     df_long \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(ret)\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\utils\\parallel.py:72\u001B[0m, in \u001B[0;36mparallelize\u001B[1;34m(fun, iter, meta, backend, backend_params)\u001B[0m\n\u001B[0;32m     69\u001B[0m backend_name \u001B[38;5;241m=\u001B[39m backend_dict[backend]\n\u001B[0;32m     70\u001B[0m para_fun \u001B[38;5;241m=\u001B[39m para_dict[backend_name]\n\u001B[1;32m---> 72\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[43mpara_fun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfun\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmeta\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbackend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbackend\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbackend_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbackend_params\u001B[49m\n\u001B[0;32m     74\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\utils\\parallel.py:92\u001B[0m, in \u001B[0;36m_parallelize_none\u001B[1;34m(fun, iter, meta, backend, backend_params)\u001B[0m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_parallelize_none\u001B[39m(fun, \u001B[38;5;28miter\u001B[39m, meta, backend, backend_params):\n\u001B[0;32m     91\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Execute loop via simple sequential list comprehension.\"\"\"\u001B[39;00m\n\u001B[1;32m---> 92\u001B[0m     ret \u001B[38;5;241m=\u001B[39m [fun(x, meta\u001B[38;5;241m=\u001B[39mmeta) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28miter\u001B[39m]\n\u001B[0;32m     93\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\utils\\parallel.py:92\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_parallelize_none\u001B[39m(fun, \u001B[38;5;28miter\u001B[39m, meta, backend, backend_params):\n\u001B[0;32m     91\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Execute loop via simple sequential list comprehension.\"\"\"\u001B[39;00m\n\u001B[1;32m---> 92\u001B[0m     ret \u001B[38;5;241m=\u001B[39m [\u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmeta\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28miter\u001B[39m]\n\u001B[0;32m     93\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:679\u001B[0m, in \u001B[0;36mVectorizedDF._vectorize_est_single\u001B[1;34m(self, vec_tuple, meta)\u001B[0m\n\u001B[0;32m    676\u001B[0m     args_i[varname_of_self] \u001B[38;5;241m=\u001B[39m group\n\u001B[0;32m    678\u001B[0m est_i_method \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(est_i, method)\n\u001B[1;32m--> 679\u001B[0m est_i_result \u001B[38;5;241m=\u001B[39m est_i_method(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39margs_i)\n\u001B[0;32m    681\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m group_name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    682\u001B[0m     group_name \u001B[38;5;241m=\u001B[39m rowname_default\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\forecasting\\base\\_base.py:2487\u001B[0m, in \u001B[0;36m_BaseGlobalForecaster.predict\u001B[1;34m(self, fh, X, y)\u001B[0m\n\u001B[0;32m   2485\u001B[0m \u001B[38;5;66;03m# we call the ordinary _predict if no looping/vectorization needed\u001B[39;00m\n\u001B[0;32m   2486\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_vectorized:\n\u001B[1;32m-> 2487\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfh\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfh\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_inner\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_inner\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2488\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2489\u001B[0m     \u001B[38;5;66;03m# otherwise we call the vectorized version of predict\u001B[39;00m\n\u001B[0;32m   2490\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vectorize(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredict\u001B[39m\u001B[38;5;124m\"\u001B[39m, y\u001B[38;5;241m=\u001B[39my_inner, X\u001B[38;5;241m=\u001B[39mX_inner, fh\u001B[38;5;241m=\u001B[39mfh)\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\forecasting\\base\\adapters\\_neuralforecast.py:533\u001B[0m, in \u001B[0;36m_NeuralForecastAdapter._predict\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m    528\u001B[0m id_ins \u001B[38;5;241m=\u001B[39m pandas\u001B[38;5;241m.\u001B[39mDataFrame(\n\u001B[0;32m    529\u001B[0m     data\u001B[38;5;241m=\u001B[39mins, index\u001B[38;5;241m=\u001B[39mid_int, columns\u001B[38;5;241m=\u001B[39mnew_index_names[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    530\u001B[0m )\n\u001B[0;32m    531\u001B[0m id_ins \u001B[38;5;241m=\u001B[39m id_ins\u001B[38;5;241m.\u001B[39mdrop_duplicates()\n\u001B[0;32m    532\u001B[0m final_predictions \u001B[38;5;241m=\u001B[39m pandas\u001B[38;5;241m.\u001B[39mconcat(\n\u001B[1;32m--> 533\u001B[0m     (model_forecasts, \u001B[43mid_ins\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmodel_forecasts\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtolist\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m),\n\u001B[0;32m    534\u001B[0m     axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m    535\u001B[0m )\n\u001B[0;32m    536\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_PeriodIndex:\n\u001B[0;32m    537\u001B[0m     time_idx \u001B[38;5;241m=\u001B[39m pandas\u001B[38;5;241m.\u001B[39mDatetimeIndex(final_predictions[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtime_col])\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\pandas\\core\\indexing.py:1191\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1189\u001B[0m maybe_callable \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39mapply_if_callable(key, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj)\n\u001B[0;32m   1190\u001B[0m maybe_callable \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001B[1;32m-> 1191\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmaybe_callable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\pandas\\core\\indexing.py:1420\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_axis\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1417\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(key, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mndim\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m key\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1418\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot index with multidimensional key\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1420\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_iterable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1422\u001B[0m \u001B[38;5;66;03m# nested tuple slicing\u001B[39;00m\n\u001B[0;32m   1423\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_nested_tuple(key, labels):\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\pandas\\core\\indexing.py:1360\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_iterable\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1357\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_key(key, axis)\n\u001B[0;32m   1359\u001B[0m \u001B[38;5;66;03m# A collection of keys\u001B[39;00m\n\u001B[1;32m-> 1360\u001B[0m keyarr, indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_listlike_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1361\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_reindex_with_indexers(\n\u001B[0;32m   1362\u001B[0m     {axis: [keyarr, indexer]}, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, allow_dups\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1363\u001B[0m )\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\pandas\\core\\indexing.py:1558\u001B[0m, in \u001B[0;36m_LocIndexer._get_listlike_indexer\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1555\u001B[0m ax \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis(axis)\n\u001B[0;32m   1556\u001B[0m axis_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis_name(axis)\n\u001B[1;32m-> 1558\u001B[0m keyarr, indexer \u001B[38;5;241m=\u001B[39m \u001B[43max\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1560\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m keyarr, indexer\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[1;34m(self, key, axis_name)\u001B[0m\n\u001B[0;32m   6197\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6198\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[1;32m-> 6200\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6202\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[0;32m   6203\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[0;32m   6204\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[1;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[0;32m   6249\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6251\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[1;32m-> 6252\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: '[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229] not in index'"
     ]
    }
   ],
   "source": [
    "LSTMforecaster = LSTMmodel.LSTMforecaster(train_data, test_data, ['HR', 'O2Sat', 'SBP', 'MAP', 'DBP', 'Resp', 'Temp'])\n",
    "LSTMforecaster.fit()\n",
    "LSTMforecasts = LSTMforecaster.predict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-02T20:31:08.444899Z",
     "start_time": "2025-04-02T20:30:29.044144900Z"
    }
   },
   "id": "f0786430fa67559e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LSTMforecaster.evaluate_model(LSTMforecasts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-02T13:27:36.483837400Z"
    }
   },
   "id": "ed77023f696a3632"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LSTMforecaster.plot_forecast(LSTMforecasts)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a35d92dce7355b11"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6028\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-02T17:28:37.968183200Z",
     "start_time": "2025-04-02T17:28:37.940252500Z"
    }
   },
   "id": "d165f2f4556945dd"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Patient 1: Dropping — constant columns found\n",
      "Patient 2: Less than 50 time points — skipping.\n",
      "Patient 3: Less than 50 time points — skipping.\n",
      "Patient 4: Less than 50 time points — skipping.\n",
      "Patient 5: Less than 50 time points — skipping.\n",
      "Patient 6: Less than 50 time points — skipping.\n",
      "Patient 7: Less than 50 time points — skipping.\n",
      "Patient 8: Less than 50 time points — skipping.\n",
      "Patient 10: Less than 50 time points — skipping.\n",
      "Patient 11: Less than 50 time points — skipping.\n",
      "Patient 12: Less than 50 time points — skipping.\n",
      "Patient 13: Less than 50 time points — skipping.\n",
      "Patient 14: Less than 50 time points — skipping.\n",
      "Patient 15: Less than 50 time points — skipping.\n",
      "Patient 16: Less than 50 time points — skipping.\n",
      "Patient 17: Less than 50 time points — skipping.\n",
      "Patient 18: Dropping — constant columns found\n",
      "Patient 19: Less than 50 time points — skipping.\n",
      "Patient 20: Less than 50 time points — skipping.\n",
      "Patient 21: Dropping — constant columns found\n",
      "Patient 22: Less than 50 time points — skipping.\n",
      "Patient 23: Less than 50 time points — skipping.\n",
      "Patient 25: Dropping — constant columns found\n",
      "Patient 26: Less than 50 time points — skipping.\n",
      "Patient 27: Less than 50 time points — skipping.\n",
      "Patient 28: Less than 50 time points — skipping.\n",
      "Patient 29: Less than 50 time points — skipping.\n",
      "Patient 30: Less than 50 time points — skipping.\n",
      "Patient 31: Dropping — constant columns found\n",
      "Patient 32: Dropping — constant columns found\n",
      "Patient 33: Less than 50 time points — skipping.\n",
      "Patient 34: Less than 50 time points — skipping.\n",
      "Patient 35: Less than 50 time points — skipping.\n",
      "Patient 36: Less than 50 time points — skipping.\n",
      "Patient 37: Less than 50 time points — skipping.\n",
      "Patient 38: Less than 50 time points — skipping.\n",
      "Patient 39: Less than 50 time points — skipping.\n",
      "Patient 40: Less than 50 time points — skipping.\n",
      "Patient 41: Less than 50 time points — skipping.\n",
      "Patient 43: Less than 50 time points — skipping.\n",
      "Patient 44: Less than 50 time points — skipping.\n",
      "Patient 45: Less than 50 time points — skipping.\n",
      "Patient 46: Dropping — constant columns found\n",
      "Patient 47: Less than 50 time points — skipping.\n",
      "Patient 48: Less than 50 time points — skipping.\n",
      "Patient 49: Less than 50 time points — skipping.\n",
      "Patient 50: Dropping — constant columns found\n",
      "Patient 51: Less than 50 time points — skipping.\n",
      "Patient 52: Less than 50 time points — skipping.\n",
      "Patient 53: Less than 50 time points — skipping.\n",
      "Patient 54: Dropping — constant columns found\n",
      "Patient 55: Less than 50 time points — skipping.\n",
      "Patient 56: Less than 50 time points — skipping.\n",
      "Patient 57: Less than 50 time points — skipping.\n",
      "Patient 58: Less than 50 time points — skipping.\n",
      "Patient 59: Less than 50 time points — skipping.\n",
      "Patient 60: Less than 50 time points — skipping.\n",
      "Patient 61: Less than 50 time points — skipping.\n",
      "Patient 62: Less than 50 time points — skipping.\n",
      "Patient 63: Less than 50 time points — skipping.\n",
      "Patient 64: Less than 50 time points — skipping.\n",
      "Patient 65: Less than 50 time points — skipping.\n",
      "Patient 66: Less than 50 time points — skipping.\n",
      "Patient 67: Less than 50 time points — skipping.\n",
      "Patient 68: Less than 50 time points — skipping.\n",
      "Patient 69: Less than 50 time points — skipping.\n",
      "Patient 70: Less than 50 time points — skipping.\n",
      "Patient 71: Dropping — constant columns found\n",
      "Patient 72: Less than 50 time points — skipping.\n",
      "Patient 73: Less than 50 time points — skipping.\n",
      "Patient 74: Less than 50 time points — skipping.\n",
      "Patient 75: Less than 50 time points — skipping.\n",
      "Patient 76: Dropping — constant columns found\n",
      "Patient 77: Less than 50 time points — skipping.\n",
      "Patient 79: Less than 50 time points — skipping.\n",
      "Patient 80: Less than 50 time points — skipping.\n",
      "Patient 81: Less than 50 time points — skipping.\n",
      "Patient 82: Less than 50 time points — skipping.\n",
      "Patient 83: Dropping — constant columns found\n",
      "Patient 84: Less than 50 time points — skipping.\n",
      "Patient 85: Dropping — constant columns found\n",
      "Patient 86: Less than 50 time points — skipping.\n",
      "Patient 87: Less than 50 time points — skipping.\n",
      "Patient 88: Less than 50 time points — skipping.\n",
      "Patient 89: Less than 50 time points — skipping.\n",
      "Patient 90: Less than 50 time points — skipping.\n",
      "Patient 91: Dropping — constant columns found\n",
      "Patient 92: Less than 50 time points — skipping.\n",
      "Patient 93: Less than 50 time points — skipping.\n",
      "Patient 94: Less than 50 time points — skipping.\n",
      "Patient 95: Less than 50 time points — skipping.\n",
      "Patient 96: Less than 50 time points — skipping.\n",
      "Patient 97: Less than 50 time points — skipping.\n",
      "Patient 98: Dropping — constant columns found\n",
      "Patient 99: Less than 50 time points — skipping.\n",
      "Patient 100: Less than 50 time points — skipping.\n",
      "Patient 2: Dropping — constant columns found\n",
      "Patient 3: Dropping — constant columns found\n"
     ]
    }
   ],
   "source": [
    "import LSTMmodel2\n",
    "\n",
    "myloader = loadDataForSKtime.PatientTimeSeriesLoader(\n",
    "    \"C:/Users/emily/Documents/DissertationProject/training/training_setA_csv\", ['HR', 'Temp', 'PTT', 'Platelets', 'WBC', 'Glucose'])\n",
    "df = myloader.load_data_LSTM(100)\n",
    "train_data, test_data = myloader.split_train_test_LSTM(df)\n",
    "\n",
    "target_df_train, target_df_test, exogenous_df_train, exogenous_df_test = myloader.target_split(train_data, test_data, ['HR'], ['HR', 'Temp', 'PTT', 'Platelets', 'WBC', 'Glucose'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T11:51:11.391265400Z",
     "start_time": "2025-04-06T11:51:10.291219200Z"
    }
   },
   "id": "c0f94a78ee8de41f"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['HR', 'Temp', 'PTT', 'Platelets', 'WBC', 'Glucose'], dtype='object')"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exogenous_df_train.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T11:38:27.404169500Z",
     "start_time": "2025-04-06T11:38:27.363739100Z"
    }
   },
   "id": "bf35679a27884916"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "HR_LSTM = LSTMmodel2.LSTMforecaster2(target_df_train, target_df_test, exogenous_df_train, exogenous_df_test, ['HR', 'Temp', 'PTT', 'Platelets', 'WBC', 'Glucose'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T11:51:16.040675400Z",
     "start_time": "2025-04-06T11:51:16.015597400Z"
    }
   },
   "id": "78f4863c74f5c0e6"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:138: UserWarning: Input size too small. Automatically setting input size to 3 * horizon = 9\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:146: UserWarning: Inference input size too small. Automatically setting inference input size to input_size = 9\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\models\\lstm.py:161: UserWarning: context_size is deprecated and will be removed in future versions.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:535: UserWarning: val_check_steps is greater than max_steps, setting val_check_steps to max_steps.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder | LSTM          | 488 K  | train\n",
      "4 | mlp_decoder  | MLP           | 41.6 K | train\n",
      "-------------------------------------------------------\n",
      "530 K     Trainable params\n",
      "0         Non-trainable params\n",
      "530 K     Total params\n",
      "2.122     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7498285bf10741a0991b6e167c8a073c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c839daf561af4db3ac5a8d683f0a0b19"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "402abdc42f8b47a4843587f9c003f7e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=10` reached.\n"
     ]
    }
   ],
   "source": [
    "HR_LSTM.fit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T11:51:23.455407200Z",
     "start_time": "2025-04-06T11:51:17.410753600Z"
    }
   },
   "id": "dcf10b35909ee5cf"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is fitted. Generating forecasts...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Missing exogeneous data, 'futr_exog_list' is non-empty.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m LSTMforecasts \u001B[38;5;241m=\u001B[39m \u001B[43mHR_LSTM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\LSTM\\LSTMmodel2.py:37\u001B[0m, in \u001B[0;36mLSTMforecaster2.predict\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     32\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel is fitted. Generating forecasts...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     33\u001B[0m \u001B[38;5;66;03m# fh = ForecastingHorizon([44, 45, 46, 47, 48, 49], is_relative=False)\u001B[39;00m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;66;03m# print(\"Internal fh:\", self.forecaster._fh)\u001B[39;00m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;66;03m# print(\"Forecaster cutoff:\", self.forecaster.cutoff)\u001B[39;00m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;66;03m# print(\"ForecastingHorizon:\", fh)\u001B[39;00m\n\u001B[1;32m---> 37\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforecaster\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\forecasting\\base\\_base.py:2487\u001B[0m, in \u001B[0;36m_BaseGlobalForecaster.predict\u001B[1;34m(self, fh, X, y)\u001B[0m\n\u001B[0;32m   2485\u001B[0m \u001B[38;5;66;03m# we call the ordinary _predict if no looping/vectorization needed\u001B[39;00m\n\u001B[0;32m   2486\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_vectorized:\n\u001B[1;32m-> 2487\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfh\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfh\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_inner\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_inner\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2488\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2489\u001B[0m     \u001B[38;5;66;03m# otherwise we call the vectorized version of predict\u001B[39;00m\n\u001B[0;32m   2490\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vectorize(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredict\u001B[39m\u001B[38;5;124m\"\u001B[39m, y\u001B[38;5;241m=\u001B[39my_inner, X\u001B[38;5;241m=\u001B[39mX_inner, fh\u001B[38;5;241m=\u001B[39mfh)\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\forecasting\\base\\adapters\\_neuralforecast.py:465\u001B[0m, in \u001B[0;36m_NeuralForecastAdapter._predict\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m    462\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_y\n\u001B[0;32m    464\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfutr_exog_list \u001B[38;5;129;01mand\u001B[39;00m X \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 465\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mMissing exogeneous data, \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfutr_exog_list\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is non-empty.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    467\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfutr_exog_list:\n\u001B[0;32m    468\u001B[0m     X_time_index \u001B[38;5;241m=\u001B[39m X\u001B[38;5;241m.\u001B[39mindex\u001B[38;5;241m.\u001B[39mget_level_values(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: Missing exogeneous data, 'futr_exog_list' is non-empty."
     ]
    }
   ],
   "source": [
    "LSTMforecasts = HR_LSTM.predict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T11:51:42.361999200Z",
     "start_time": "2025-04-06T11:51:42.182260800Z"
    }
   },
   "id": "563ee9f40692c158"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6d5be32a25d94d9d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
