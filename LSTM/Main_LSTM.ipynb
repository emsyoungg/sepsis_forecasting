{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-06T13:59:17.059360300Z",
     "start_time": "2025-04-06T13:59:12.122771Z"
    }
   },
   "outputs": [],
   "source": [
    "import loadDataForSKtime\n",
    "import LSTMmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Patient 1: Dropping — constant columns found\n",
      "Patient 2: Less than 50 time points — skipping.\n",
      "Patient 3: Less than 50 time points — skipping.\n",
      "Patient 4: Less than 50 time points — skipping.\n",
      "Patient 5: Less than 50 time points — skipping.\n",
      "Patient 6: Less than 50 time points — skipping.\n",
      "Patient 7: Less than 50 time points — skipping.\n",
      "Patient 8: Less than 50 time points — skipping.\n",
      "Patient 10: Less than 50 time points — skipping.\n",
      "Patient 11: Less than 50 time points — skipping.\n",
      "Patient 12: Less than 50 time points — skipping.\n",
      "Patient 13: Less than 50 time points — skipping.\n",
      "Patient 14: Less than 50 time points — skipping.\n",
      "Patient 15: Less than 50 time points — skipping.\n",
      "Patient 16: Less than 50 time points — skipping.\n",
      "Patient 17: Less than 50 time points — skipping.\n",
      "Patient 19: Less than 50 time points — skipping.\n",
      "Patient 20: Less than 50 time points — skipping.\n",
      "Patient 22: Less than 50 time points — skipping.\n",
      "Patient 23: Less than 50 time points — skipping.\n",
      "Patient 24: Dropping — constant columns found\n",
      "Patient 25: Dropping — constant columns found\n",
      "Patient 26: Less than 50 time points — skipping.\n",
      "Patient 27: Less than 50 time points — skipping.\n",
      "Patient 28: Less than 50 time points — skipping.\n",
      "Patient 29: Less than 50 time points — skipping.\n",
      "Patient 30: Less than 50 time points — skipping.\n",
      "Patient 32: Dropping — constant columns found\n",
      "Patient 33: Less than 50 time points — skipping.\n",
      "Patient 34: Less than 50 time points — skipping.\n",
      "Patient 35: Less than 50 time points — skipping.\n",
      "Patient 36: Less than 50 time points — skipping.\n",
      "Patient 37: Less than 50 time points — skipping.\n",
      "Patient 38: Less than 50 time points — skipping.\n",
      "Patient 39: Less than 50 time points — skipping.\n",
      "Patient 40: Less than 50 time points — skipping.\n",
      "Patient 41: Less than 50 time points — skipping.\n",
      "Patient 43: Less than 50 time points — skipping.\n",
      "Patient 44: Less than 50 time points — skipping.\n",
      "Patient 45: Less than 50 time points — skipping.\n",
      "Patient 47: Less than 50 time points — skipping.\n",
      "Patient 48: Less than 50 time points — skipping.\n",
      "Patient 49: Less than 50 time points — skipping.\n",
      "Patient 50: Dropping — constant columns found\n",
      "Patient 51: Less than 50 time points — skipping.\n",
      "Patient 52: Less than 50 time points — skipping.\n",
      "Patient 53: Less than 50 time points — skipping.\n",
      "Patient 55: Less than 50 time points — skipping.\n",
      "Patient 56: Less than 50 time points — skipping.\n",
      "Patient 57: Less than 50 time points — skipping.\n",
      "Patient 58: Less than 50 time points — skipping.\n",
      "Patient 59: Less than 50 time points — skipping.\n",
      "Patient 60: Less than 50 time points — skipping.\n",
      "Patient 61: Less than 50 time points — skipping.\n",
      "Patient 62: Less than 50 time points — skipping.\n",
      "Patient 63: Less than 50 time points — skipping.\n",
      "Patient 64: Less than 50 time points — skipping.\n",
      "Patient 65: Less than 50 time points — skipping.\n",
      "Patient 66: Less than 50 time points — skipping.\n",
      "Patient 67: Less than 50 time points — skipping.\n",
      "Patient 68: Less than 50 time points — skipping.\n",
      "Patient 69: Less than 50 time points — skipping.\n",
      "Patient 70: Less than 50 time points — skipping.\n",
      "Patient 72: Less than 50 time points — skipping.\n",
      "Patient 73: Less than 50 time points — skipping.\n",
      "Patient 74: Less than 50 time points — skipping.\n",
      "Patient 75: Less than 50 time points — skipping.\n",
      "Patient 77: Less than 50 time points — skipping.\n",
      "Patient 79: Less than 50 time points — skipping.\n",
      "Patient 80: Less than 50 time points — skipping.\n",
      "Patient 81: Less than 50 time points — skipping.\n",
      "Patient 82: Less than 50 time points — skipping.\n",
      "Patient 84: Less than 50 time points — skipping.\n",
      "Patient 85: Dropping — constant columns found\n",
      "Patient 86: Less than 50 time points — skipping.\n",
      "Patient 87: Less than 50 time points — skipping.\n",
      "Patient 88: Less than 50 time points — skipping.\n",
      "Patient 89: Less than 50 time points — skipping.\n",
      "Patient 90: Less than 50 time points — skipping.\n",
      "Patient 92: Less than 50 time points — skipping.\n",
      "Patient 93: Less than 50 time points — skipping.\n",
      "Patient 94: Less than 50 time points — skipping.\n",
      "Patient 95: Less than 50 time points — skipping.\n",
      "Patient 96: Less than 50 time points — skipping.\n",
      "Patient 97: Less than 50 time points — skipping.\n",
      "Patient 98: Dropping — constant columns found\n",
      "Patient 99: Less than 50 time points — skipping.\n",
      "Patient 100: Less than 50 time points — skipping.\n",
      "Patient 1: Dropping — constant columns found\n",
      "Patient 9: Dropping — constant columns found\n"
     ]
    }
   ],
   "source": [
    "loader = loadDataForSKtime.PatientTimeSeriesLoader(\n",
    "    \"C:/Users/emily/Documents/DissertationProject/training/training_setA_csv\", ['HR', 'O2Sat', 'SBP', 'MAP', 'DBP', 'Resp', 'Temp'])\n",
    "df = loader.load_data_LSTM(100)\n",
    "train_data, test_data = loader.split_train_test_LSTM(df)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-04T13:07:03.549955200Z",
     "start_time": "2025-04-04T13:07:01.585704300Z"
    }
   },
   "id": "aeffc725bcbf08d3"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                      HR  O2Sat    SBP    MAP   DBP  Resp   Temp\nPatient_ID ICULOS                                               \n0          0       117.0   99.0  116.0  97.00  81.0  20.0  36.00\n           1       117.0   99.0  116.0  97.00  81.0  20.0  36.00\n           2       117.0   99.0  116.0  97.00  81.0  20.0  36.00\n           3       117.0   99.0  116.0  97.00  81.0  20.0  36.00\n           4       117.0   99.0  116.0  97.00  81.0  20.0  36.00\n...                  ...    ...    ...    ...   ...   ...    ...\n9          39      117.0   95.0  125.0  71.67  65.0  24.5  37.39\n           40      106.0   95.0  116.0  66.00  47.0  23.0  37.67\n           41      113.0   97.0  102.0  72.00  55.0  22.0  37.67\n           42       98.0   98.0  108.5  68.00  53.0  19.0  37.67\n           43       95.0   97.0  111.0  65.00  48.0  20.0  37.67\n\n[440 rows x 7 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>HR</th>\n      <th>O2Sat</th>\n      <th>SBP</th>\n      <th>MAP</th>\n      <th>DBP</th>\n      <th>Resp</th>\n      <th>Temp</th>\n    </tr>\n    <tr>\n      <th>Patient_ID</th>\n      <th>ICULOS</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">0</th>\n      <th>0</th>\n      <td>117.0</td>\n      <td>99.0</td>\n      <td>116.0</td>\n      <td>97.00</td>\n      <td>81.0</td>\n      <td>20.0</td>\n      <td>36.00</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>117.0</td>\n      <td>99.0</td>\n      <td>116.0</td>\n      <td>97.00</td>\n      <td>81.0</td>\n      <td>20.0</td>\n      <td>36.00</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>117.0</td>\n      <td>99.0</td>\n      <td>116.0</td>\n      <td>97.00</td>\n      <td>81.0</td>\n      <td>20.0</td>\n      <td>36.00</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>117.0</td>\n      <td>99.0</td>\n      <td>116.0</td>\n      <td>97.00</td>\n      <td>81.0</td>\n      <td>20.0</td>\n      <td>36.00</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>117.0</td>\n      <td>99.0</td>\n      <td>116.0</td>\n      <td>97.00</td>\n      <td>81.0</td>\n      <td>20.0</td>\n      <td>36.00</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">9</th>\n      <th>39</th>\n      <td>117.0</td>\n      <td>95.0</td>\n      <td>125.0</td>\n      <td>71.67</td>\n      <td>65.0</td>\n      <td>24.5</td>\n      <td>37.39</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>106.0</td>\n      <td>95.0</td>\n      <td>116.0</td>\n      <td>66.00</td>\n      <td>47.0</td>\n      <td>23.0</td>\n      <td>37.67</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>113.0</td>\n      <td>97.0</td>\n      <td>102.0</td>\n      <td>72.00</td>\n      <td>55.0</td>\n      <td>22.0</td>\n      <td>37.67</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>98.0</td>\n      <td>98.0</td>\n      <td>108.5</td>\n      <td>68.00</td>\n      <td>53.0</td>\n      <td>19.0</td>\n      <td>37.67</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>95.0</td>\n      <td>97.0</td>\n      <td>111.0</td>\n      <td>65.00</td>\n      <td>48.0</td>\n      <td>20.0</td>\n      <td>37.67</td>\n    </tr>\n  </tbody>\n</table>\n<p>440 rows × 7 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-04T13:07:10.581187600Z",
     "start_time": "2025-04-04T13:07:10.520444Z"
    }
   },
   "id": "203a1db0da610a6d"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import pickle\n",
    "train_data.to_pickle(\"train_data_small.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-02T15:41:11.129572700Z",
     "start_time": "2025-04-02T15:41:11.077777800Z"
    }
   },
   "id": "ef219eaa891b9d0c"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_pickle(\"train_data_small.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-02T14:04:43.671236800Z",
     "start_time": "2025-04-02T14:04:43.651980800Z"
    }
   },
   "id": "4fac8a1f3ad5bbcb"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train IDs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136]\n",
      "Test  IDs: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train IDs:\", sorted(train_data.index.get_level_values(\"Patient_ID\").unique()))\n",
    "print(\"Test  IDs:\", sorted(test_data.index.get_level_values(\"Patient_ID\").unique()))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-02T15:13:51.032535900Z",
     "start_time": "2025-04-02T15:13:50.982345Z"
    }
   },
   "id": "a42026dd9f1e1016"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sktime.datatypes import mtype\n",
    "import sktime.datatypes\n",
    "sktime.datatypes.check_raise(train_data, \"pd-multiindex\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-03T16:51:38.281137500Z",
     "start_time": "2025-04-03T16:51:38.158439900Z"
    }
   },
   "id": "9857a7c8f0289855"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "LSTMforecaster = LSTMmodel.LSTMforecaster(train_data, test_data, ['HR', 'O2Sat', 'SBP', 'MAP', 'DBP', 'Resp', 'Temp'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-04T13:09:18.324277200Z",
     "start_time": "2025-04-04T13:09:18.295091100Z"
    }
   },
   "id": "d161647e845e7926"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LSTMforecaster.fit_predict()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "89fe33881449579b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "https://www.sktime.net/en/stable/api_reference/auto_generated/sktime.datatypes._panel._check.PanelPdMultiIndex.html#sktime.datatypes._panel._check.PanelPdMultiIndex"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b578886c0e5532df"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:138: UserWarning: Input size too small. Automatically setting input size to 3 * horizon = 138\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:146: UserWarning: Inference input size too small. Automatically setting inference input size to input_size = 138\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\models\\lstm.py:161: UserWarning: context_size is deprecated and will be removed in future versions.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:535: UserWarning: val_check_steps is greater than max_steps, setting val_check_steps to max_steps.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder | LSTM          | 484 K  | train\n",
      "4 | mlp_decoder  | MLP           | 40.4 K | train\n",
      "-------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "0         Non-trainable params\n",
      "524 K     Total params\n",
      "2.098     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eb9df97369bf4444a18dac47ccfa77dc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1d19cbe2123c4d87b19bbaf47719dbcf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "121b485369cb439d87736672bfa1b290"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=10` reached.\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:138: UserWarning: Input size too small. Automatically setting input size to 3 * horizon = 138\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:146: UserWarning: Inference input size too small. Automatically setting inference input size to input_size = 138\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\models\\lstm.py:161: UserWarning: context_size is deprecated and will be removed in future versions.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:535: UserWarning: val_check_steps is greater than max_steps, setting val_check_steps to max_steps.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder | LSTM          | 484 K  | train\n",
      "4 | mlp_decoder  | MLP           | 40.4 K | train\n",
      "-------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "0         Non-trainable params\n",
      "524 K     Total params\n",
      "2.098     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06a1b4005b5941d6abbe81b9ceb2c27d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f3a1c5546c14477cbcad6dca9b3bb177"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e5f3b1ad210642c6aa1d3ca7fc160402"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=10` reached.\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:138: UserWarning: Input size too small. Automatically setting input size to 3 * horizon = 138\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:146: UserWarning: Inference input size too small. Automatically setting inference input size to input_size = 138\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\models\\lstm.py:161: UserWarning: context_size is deprecated and will be removed in future versions.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:535: UserWarning: val_check_steps is greater than max_steps, setting val_check_steps to max_steps.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder | LSTM          | 484 K  | train\n",
      "4 | mlp_decoder  | MLP           | 40.4 K | train\n",
      "-------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "0         Non-trainable params\n",
      "524 K     Total params\n",
      "2.098     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f68b7852971a4cd7a434b885c9a705c3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71b85308be084a2cac19b5d8291d1f58"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "364e90779e454db087ae7de969f9b971"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=10` reached.\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:138: UserWarning: Input size too small. Automatically setting input size to 3 * horizon = 138\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:146: UserWarning: Inference input size too small. Automatically setting inference input size to input_size = 138\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\models\\lstm.py:161: UserWarning: context_size is deprecated and will be removed in future versions.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:535: UserWarning: val_check_steps is greater than max_steps, setting val_check_steps to max_steps.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder | LSTM          | 484 K  | train\n",
      "4 | mlp_decoder  | MLP           | 40.4 K | train\n",
      "-------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "0         Non-trainable params\n",
      "524 K     Total params\n",
      "2.098     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3e4a85d7d05c46fa92de8537c20e413c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ddd84983fc114c1088cd2da1f0d5a881"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a8db773008a649e5a6b6a12b63e81608"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=10` reached.\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:138: UserWarning: Input size too small. Automatically setting input size to 3 * horizon = 138\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:146: UserWarning: Inference input size too small. Automatically setting inference input size to input_size = 138\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\models\\lstm.py:161: UserWarning: context_size is deprecated and will be removed in future versions.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:535: UserWarning: val_check_steps is greater than max_steps, setting val_check_steps to max_steps.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder | LSTM          | 484 K  | train\n",
      "4 | mlp_decoder  | MLP           | 40.4 K | train\n",
      "-------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "0         Non-trainable params\n",
      "524 K     Total params\n",
      "2.098     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e354ac37bdbc4045be9759281761e44b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4cb5857545884624bc42066cbe3ea94b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d5afb569f1c34ef4a76a539de405d884"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=10` reached.\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:138: UserWarning: Input size too small. Automatically setting input size to 3 * horizon = 138\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:146: UserWarning: Inference input size too small. Automatically setting inference input size to input_size = 138\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\models\\lstm.py:161: UserWarning: context_size is deprecated and will be removed in future versions.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:535: UserWarning: val_check_steps is greater than max_steps, setting val_check_steps to max_steps.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder | LSTM          | 484 K  | train\n",
      "4 | mlp_decoder  | MLP           | 40.4 K | train\n",
      "-------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "0         Non-trainable params\n",
      "524 K     Total params\n",
      "2.098     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "18e6b9cb276d4670ab9eee0a8b80c66d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23910ed6bbe547cfa2268b79be52d159"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0062c2f014704e408f3f58ddbfb7b026"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=10` reached.\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:138: UserWarning: Input size too small. Automatically setting input size to 3 * horizon = 138\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:146: UserWarning: Inference input size too small. Automatically setting inference input size to input_size = 138\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\models\\lstm.py:161: UserWarning: context_size is deprecated and will be removed in future versions.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:535: UserWarning: val_check_steps is greater than max_steps, setting val_check_steps to max_steps.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder | LSTM          | 484 K  | train\n",
      "4 | mlp_decoder  | MLP           | 40.4 K | train\n",
      "-------------------------------------------------------\n",
      "524 K     Trainable params\n",
      "0         Non-trainable params\n",
      "524 K     Total params\n",
      "2.098     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71cab6d580a04be1a232cad32763722c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a386af265ef3486094711b9a886011af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eba91c62c7bf4455b3db1bcc07e8396c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=10` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is fitted. Generating forecasts...\n"
     ]
    },
    {
     "data": {
      "text/plain": "Predicting: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8ef79bce37c42e3b0e5ec136f0f9b20"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[4], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m LSTMforecaster \u001B[38;5;241m=\u001B[39m LSTMmodel\u001B[38;5;241m.\u001B[39mLSTMforecaster(train_data, test_data, [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mHR\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mO2Sat\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mSBP\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMAP\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDBP\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mResp\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTemp\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m      2\u001B[0m LSTMforecaster\u001B[38;5;241m.\u001B[39mfit()\n\u001B[1;32m----> 3\u001B[0m LSTMforecasts \u001B[38;5;241m=\u001B[39m \u001B[43mLSTMforecaster\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\LSTMmodel.py:36\u001B[0m, in \u001B[0;36mLSTMforecaster.predict\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     31\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel is fitted. Generating forecasts...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     32\u001B[0m \u001B[38;5;66;03m# fh = ForecastingHorizon([44, 45, 46, 47, 48, 49], is_relative=False)\u001B[39;00m\n\u001B[0;32m     33\u001B[0m \u001B[38;5;66;03m# print(\"Internal fh:\", self.forecaster._fh)\u001B[39;00m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;66;03m# print(\"Forecaster cutoff:\", self.forecaster.cutoff)\u001B[39;00m\n\u001B[0;32m     35\u001B[0m \u001B[38;5;66;03m# print(\"ForecastingHorizon:\", fh)\u001B[39;00m\n\u001B[1;32m---> 36\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforecaster\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\forecasting\\base\\_base.py:2490\u001B[0m, in \u001B[0;36m_BaseGlobalForecaster.predict\u001B[1;34m(self, fh, X, y)\u001B[0m\n\u001B[0;32m   2487\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_predict(fh\u001B[38;5;241m=\u001B[39mfh, X\u001B[38;5;241m=\u001B[39mX_inner, y\u001B[38;5;241m=\u001B[39my_inner)\n\u001B[0;32m   2488\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2489\u001B[0m     \u001B[38;5;66;03m# otherwise we call the vectorized version of predict\u001B[39;00m\n\u001B[1;32m-> 2490\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_vectorize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mpredict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_inner\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_inner\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfh\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfh\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2492\u001B[0m \u001B[38;5;66;03m# convert to output mtype, identical with last y mtype seen\u001B[39;00m\n\u001B[0;32m   2493\u001B[0m y_out \u001B[38;5;241m=\u001B[39m convert_to(\n\u001B[0;32m   2494\u001B[0m     y_pred,\n\u001B[0;32m   2495\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_y_metadata[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmtype\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   2496\u001B[0m     store\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_converter_store_y,\n\u001B[0;32m   2497\u001B[0m     store_behaviour\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mfreeze\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   2498\u001B[0m )\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\forecasting\\base\\_base.py:2058\u001B[0m, in \u001B[0;36mBaseForecaster._vectorize\u001B[1;34m(self, methodname, **kwargs)\u001B[0m\n\u001B[0;32m   2055\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m methodname \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mupdate_predict_single\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m   2056\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_yvec \u001B[38;5;241m=\u001B[39m y\n\u001B[1;32m-> 2058\u001B[0m y_preds \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_yvec\u001B[38;5;241m.\u001B[39mvectorize_est(\n\u001B[0;32m   2059\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforecasters_,\n\u001B[0;32m   2060\u001B[0m     method\u001B[38;5;241m=\u001B[39mmethodname,\n\u001B[0;32m   2061\u001B[0m     return_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlist\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   2062\u001B[0m     backend\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_config()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbackend:parallel\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   2063\u001B[0m     backend_params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_config()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbackend:parallel:params\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[0;32m   2064\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m   2065\u001B[0m )\n\u001B[0;32m   2067\u001B[0m \u001B[38;5;66;03m# if we vectorize over columns,\u001B[39;00m\n\u001B[0;32m   2068\u001B[0m \u001B[38;5;66;03m#   we need to replace top column level with variable names - part 1\u001B[39;00m\n\u001B[0;32m   2069\u001B[0m m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mforecasters_\u001B[38;5;241m.\u001B[39mcolumns)\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:630\u001B[0m, in \u001B[0;36mVectorizedDF.vectorize_est\u001B[1;34m(self, estimator, method, args, args_rowvec, return_type, rowname_default, colname_default, varname_of_self, backend, backend_params, **kwargs)\u001B[0m\n\u001B[0;32m    616\u001B[0m vec_zip \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mzip\u001B[39m(\n\u001B[0;32m    617\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems(),\n\u001B[0;32m    618\u001B[0m     explode(args, iterate_as\u001B[38;5;241m=\u001B[39miterate_as, iterate_cols\u001B[38;5;241m=\u001B[39miterate_cols),\n\u001B[0;32m    619\u001B[0m     explode(args_rowvec, iterate_as\u001B[38;5;241m=\u001B[39miterate_as, iterate_cols\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m),\n\u001B[0;32m    620\u001B[0m     estimators,\n\u001B[0;32m    621\u001B[0m )\n\u001B[0;32m    623\u001B[0m meta \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    624\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmethod\u001B[39m\u001B[38;5;124m\"\u001B[39m: method,\n\u001B[0;32m    625\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvarname_of_self\u001B[39m\u001B[38;5;124m\"\u001B[39m: varname_of_self,\n\u001B[0;32m    626\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrowname_default\u001B[39m\u001B[38;5;124m\"\u001B[39m: rowname_default,\n\u001B[0;32m    627\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcolname_default\u001B[39m\u001B[38;5;124m\"\u001B[39m: colname_default,\n\u001B[0;32m    628\u001B[0m }\n\u001B[1;32m--> 630\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[43mparallelize\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    631\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfun\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_vectorize_est_single\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    632\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvec_zip\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    633\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmeta\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    634\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbackend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbackend\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    635\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbackend_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbackend_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    636\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    638\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m return_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpd.DataFrame\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m    639\u001B[0m     df_long \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(ret)\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\utils\\parallel.py:72\u001B[0m, in \u001B[0;36mparallelize\u001B[1;34m(fun, iter, meta, backend, backend_params)\u001B[0m\n\u001B[0;32m     69\u001B[0m backend_name \u001B[38;5;241m=\u001B[39m backend_dict[backend]\n\u001B[0;32m     70\u001B[0m para_fun \u001B[38;5;241m=\u001B[39m para_dict[backend_name]\n\u001B[1;32m---> 72\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[43mpara_fun\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfun\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfun\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43miter\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmeta\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbackend\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbackend\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbackend_params\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbackend_params\u001B[49m\n\u001B[0;32m     74\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     75\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\utils\\parallel.py:92\u001B[0m, in \u001B[0;36m_parallelize_none\u001B[1;34m(fun, iter, meta, backend, backend_params)\u001B[0m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_parallelize_none\u001B[39m(fun, \u001B[38;5;28miter\u001B[39m, meta, backend, backend_params):\n\u001B[0;32m     91\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Execute loop via simple sequential list comprehension.\"\"\"\u001B[39;00m\n\u001B[1;32m---> 92\u001B[0m     ret \u001B[38;5;241m=\u001B[39m [fun(x, meta\u001B[38;5;241m=\u001B[39mmeta) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28miter\u001B[39m]\n\u001B[0;32m     93\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\utils\\parallel.py:92\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m     90\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_parallelize_none\u001B[39m(fun, \u001B[38;5;28miter\u001B[39m, meta, backend, backend_params):\n\u001B[0;32m     91\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Execute loop via simple sequential list comprehension.\"\"\"\u001B[39;00m\n\u001B[1;32m---> 92\u001B[0m     ret \u001B[38;5;241m=\u001B[39m [\u001B[43mfun\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmeta\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmeta\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28miter\u001B[39m]\n\u001B[0;32m     93\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ret\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\datatypes\\_vectorize.py:679\u001B[0m, in \u001B[0;36mVectorizedDF._vectorize_est_single\u001B[1;34m(self, vec_tuple, meta)\u001B[0m\n\u001B[0;32m    676\u001B[0m     args_i[varname_of_self] \u001B[38;5;241m=\u001B[39m group\n\u001B[0;32m    678\u001B[0m est_i_method \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(est_i, method)\n\u001B[1;32m--> 679\u001B[0m est_i_result \u001B[38;5;241m=\u001B[39m est_i_method(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39margs_i)\n\u001B[0;32m    681\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m group_name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    682\u001B[0m     group_name \u001B[38;5;241m=\u001B[39m rowname_default\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\forecasting\\base\\_base.py:2487\u001B[0m, in \u001B[0;36m_BaseGlobalForecaster.predict\u001B[1;34m(self, fh, X, y)\u001B[0m\n\u001B[0;32m   2485\u001B[0m \u001B[38;5;66;03m# we call the ordinary _predict if no looping/vectorization needed\u001B[39;00m\n\u001B[0;32m   2486\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_vectorized:\n\u001B[1;32m-> 2487\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfh\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfh\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_inner\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_inner\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2488\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2489\u001B[0m     \u001B[38;5;66;03m# otherwise we call the vectorized version of predict\u001B[39;00m\n\u001B[0;32m   2490\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vectorize(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredict\u001B[39m\u001B[38;5;124m\"\u001B[39m, y\u001B[38;5;241m=\u001B[39my_inner, X\u001B[38;5;241m=\u001B[39mX_inner, fh\u001B[38;5;241m=\u001B[39mfh)\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\forecasting\\base\\adapters\\_neuralforecast.py:533\u001B[0m, in \u001B[0;36m_NeuralForecastAdapter._predict\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m    528\u001B[0m id_ins \u001B[38;5;241m=\u001B[39m pandas\u001B[38;5;241m.\u001B[39mDataFrame(\n\u001B[0;32m    529\u001B[0m     data\u001B[38;5;241m=\u001B[39mins, index\u001B[38;5;241m=\u001B[39mid_int, columns\u001B[38;5;241m=\u001B[39mnew_index_names[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    530\u001B[0m )\n\u001B[0;32m    531\u001B[0m id_ins \u001B[38;5;241m=\u001B[39m id_ins\u001B[38;5;241m.\u001B[39mdrop_duplicates()\n\u001B[0;32m    532\u001B[0m final_predictions \u001B[38;5;241m=\u001B[39m pandas\u001B[38;5;241m.\u001B[39mconcat(\n\u001B[1;32m--> 533\u001B[0m     (model_forecasts, \u001B[43mid_ins\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmodel_forecasts\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtolist\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m),\n\u001B[0;32m    534\u001B[0m     axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m    535\u001B[0m )\n\u001B[0;32m    536\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_PeriodIndex:\n\u001B[0;32m    537\u001B[0m     time_idx \u001B[38;5;241m=\u001B[39m pandas\u001B[38;5;241m.\u001B[39mDatetimeIndex(final_predictions[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtime_col])\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\pandas\\core\\indexing.py:1191\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1189\u001B[0m maybe_callable \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39mapply_if_callable(key, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj)\n\u001B[0;32m   1190\u001B[0m maybe_callable \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001B[1;32m-> 1191\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmaybe_callable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\pandas\\core\\indexing.py:1420\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_axis\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1417\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(key, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mndim\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m key\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1418\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot index with multidimensional key\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1420\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_iterable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1422\u001B[0m \u001B[38;5;66;03m# nested tuple slicing\u001B[39;00m\n\u001B[0;32m   1423\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_nested_tuple(key, labels):\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\pandas\\core\\indexing.py:1360\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_iterable\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1357\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_key(key, axis)\n\u001B[0;32m   1359\u001B[0m \u001B[38;5;66;03m# A collection of keys\u001B[39;00m\n\u001B[1;32m-> 1360\u001B[0m keyarr, indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_listlike_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1361\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_reindex_with_indexers(\n\u001B[0;32m   1362\u001B[0m     {axis: [keyarr, indexer]}, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, allow_dups\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1363\u001B[0m )\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\pandas\\core\\indexing.py:1558\u001B[0m, in \u001B[0;36m_LocIndexer._get_listlike_indexer\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1555\u001B[0m ax \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis(axis)\n\u001B[0;32m   1556\u001B[0m axis_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis_name(axis)\n\u001B[1;32m-> 1558\u001B[0m keyarr, indexer \u001B[38;5;241m=\u001B[39m \u001B[43max\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1560\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m keyarr, indexer\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[1;34m(self, key, axis_name)\u001B[0m\n\u001B[0;32m   6197\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6198\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[1;32m-> 6200\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6202\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[0;32m   6203\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[0;32m   6204\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[1;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[0;32m   6249\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6251\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[1;32m-> 6252\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: '[5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229] not in index'"
     ]
    }
   ],
   "source": [
    "LSTMforecaster = LSTMmodel.LSTMforecaster(train_data, test_data, ['HR', 'O2Sat', 'SBP', 'MAP', 'DBP', 'Resp', 'Temp'])\n",
    "LSTMforecaster.fit()\n",
    "LSTMforecasts = LSTMforecaster.predict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-02T20:31:08.444899Z",
     "start_time": "2025-04-02T20:30:29.044144900Z"
    }
   },
   "id": "f0786430fa67559e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LSTMforecaster.evaluate_model(LSTMforecasts)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2025-04-02T13:27:36.483837400Z"
    }
   },
   "id": "ed77023f696a3632"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LSTMforecaster.plot_forecast(LSTMforecasts)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a35d92dce7355b11"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T14:07:37.123496600Z",
     "start_time": "2025-04-06T14:07:37.104849100Z"
    }
   },
   "id": "d165f2f4556945dd"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Patient 1: Dropping — constant columns found\n",
      "Patient 2: Less than 50 time points — skipping.\n",
      "Patient 3: Less than 50 time points — skipping.\n",
      "Patient 4: Less than 50 time points — skipping.\n",
      "Patient 5: Less than 50 time points — skipping.\n",
      "Patient 6: Less than 50 time points — skipping.\n",
      "Patient 7: Less than 50 time points — skipping.\n",
      "Patient 8: Less than 50 time points — skipping.\n",
      "Patient 10: Less than 50 time points — skipping.\n",
      "Patient 11: Less than 50 time points — skipping.\n",
      "Patient 12: Less than 50 time points — skipping.\n",
      "Patient 13: Less than 50 time points — skipping.\n",
      "Patient 14: Less than 50 time points — skipping.\n",
      "Patient 15: Less than 50 time points — skipping.\n",
      "Patient 16: Less than 50 time points — skipping.\n",
      "Patient 17: Less than 50 time points — skipping.\n",
      "Patient 18: Dropping — constant columns found\n",
      "Patient 19: Less than 50 time points — skipping.\n",
      "Patient 20: Less than 50 time points — skipping.\n",
      "Patient 21: Dropping — constant columns found\n",
      "Patient 22: Less than 50 time points — skipping.\n",
      "Patient 23: Less than 50 time points — skipping.\n",
      "Patient 25: Dropping — constant columns found\n",
      "Patient 26: Less than 50 time points — skipping.\n",
      "Patient 27: Less than 50 time points — skipping.\n",
      "Patient 28: Less than 50 time points — skipping.\n",
      "Patient 29: Less than 50 time points — skipping.\n",
      "Patient 30: Less than 50 time points — skipping.\n",
      "Patient 31: Dropping — constant columns found\n",
      "Patient 32: Dropping — constant columns found\n",
      "Patient 33: Less than 50 time points — skipping.\n",
      "Patient 34: Less than 50 time points — skipping.\n",
      "Patient 35: Less than 50 time points — skipping.\n",
      "Patient 36: Less than 50 time points — skipping.\n",
      "Patient 37: Less than 50 time points — skipping.\n",
      "Patient 38: Less than 50 time points — skipping.\n",
      "Patient 39: Less than 50 time points — skipping.\n",
      "Patient 40: Less than 50 time points — skipping.\n",
      "Patient 41: Less than 50 time points — skipping.\n",
      "Patient 43: Less than 50 time points — skipping.\n",
      "Patient 44: Less than 50 time points — skipping.\n",
      "Patient 45: Less than 50 time points — skipping.\n",
      "Patient 46: Dropping — constant columns found\n",
      "Patient 47: Less than 50 time points — skipping.\n",
      "Patient 48: Less than 50 time points — skipping.\n",
      "Patient 49: Less than 50 time points — skipping.\n",
      "Patient 50: Dropping — constant columns found\n",
      "Patient 51: Less than 50 time points — skipping.\n",
      "Patient 52: Less than 50 time points — skipping.\n",
      "Patient 53: Less than 50 time points — skipping.\n",
      "Patient 54: Dropping — constant columns found\n",
      "Patient 55: Less than 50 time points — skipping.\n",
      "Patient 56: Less than 50 time points — skipping.\n",
      "Patient 57: Less than 50 time points — skipping.\n",
      "Patient 58: Less than 50 time points — skipping.\n",
      "Patient 59: Less than 50 time points — skipping.\n",
      "Patient 60: Less than 50 time points — skipping.\n",
      "Patient 61: Less than 50 time points — skipping.\n",
      "Patient 62: Less than 50 time points — skipping.\n",
      "Patient 63: Less than 50 time points — skipping.\n",
      "Patient 64: Less than 50 time points — skipping.\n",
      "Patient 65: Less than 50 time points — skipping.\n",
      "Patient 66: Less than 50 time points — skipping.\n",
      "Patient 67: Less than 50 time points — skipping.\n",
      "Patient 68: Less than 50 time points — skipping.\n",
      "Patient 69: Less than 50 time points — skipping.\n",
      "Patient 70: Less than 50 time points — skipping.\n",
      "Patient 71: Dropping — constant columns found\n",
      "Patient 72: Less than 50 time points — skipping.\n",
      "Patient 73: Less than 50 time points — skipping.\n",
      "Patient 74: Less than 50 time points — skipping.\n",
      "Patient 75: Less than 50 time points — skipping.\n",
      "Patient 76: Dropping — constant columns found\n",
      "Patient 77: Less than 50 time points — skipping.\n",
      "Patient 79: Less than 50 time points — skipping.\n",
      "Patient 80: Less than 50 time points — skipping.\n",
      "Patient 81: Less than 50 time points — skipping.\n",
      "Patient 82: Less than 50 time points — skipping.\n",
      "Patient 83: Dropping — constant columns found\n",
      "Patient 84: Less than 50 time points — skipping.\n",
      "Patient 85: Dropping — constant columns found\n",
      "Patient 86: Less than 50 time points — skipping.\n",
      "Patient 87: Less than 50 time points — skipping.\n",
      "Patient 88: Less than 50 time points — skipping.\n",
      "Patient 89: Less than 50 time points — skipping.\n",
      "Patient 90: Less than 50 time points — skipping.\n",
      "Patient 91: Dropping — constant columns found\n",
      "Patient 92: Less than 50 time points — skipping.\n",
      "Patient 93: Less than 50 time points — skipping.\n",
      "Patient 94: Less than 50 time points — skipping.\n",
      "Patient 95: Less than 50 time points — skipping.\n",
      "Patient 96: Less than 50 time points — skipping.\n",
      "Patient 97: Less than 50 time points — skipping.\n",
      "Patient 98: Dropping — constant columns found\n",
      "Patient 99: Less than 50 time points — skipping.\n",
      "Patient 100: Less than 50 time points — skipping.\n",
      "Patient 2: Dropping — constant columns found\n",
      "Patient 3: Dropping — constant columns found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emily\\Documents\\DissertationProject\\loadDataForSKtime.py:283: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_target_df[\"Patient_ID\"] = new_patient_id\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\loadDataForSKtime.py:284: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_target_df[\"ICULOS\"] = train_df.index\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\loadDataForSKtime.py:285: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_target_df[\"Patient_ID\"] = new_patient_id\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\loadDataForSKtime.py:286: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_target_df[\"ICULOS\"] = test_df.index\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\loadDataForSKtime.py:283: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_target_df[\"Patient_ID\"] = new_patient_id\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\loadDataForSKtime.py:284: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_target_df[\"ICULOS\"] = train_df.index\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\loadDataForSKtime.py:285: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_target_df[\"Patient_ID\"] = new_patient_id\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\loadDataForSKtime.py:286: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_target_df[\"ICULOS\"] = test_df.index\n"
     ]
    }
   ],
   "source": [
    "import loadDataForSKtime\n",
    "import LSTMmodel2\n",
    "\n",
    "myloader = loadDataForSKtime.PatientTimeSeriesLoader(\n",
    "    \"C:/Users/emily/Documents/DissertationProject/training/training_setA_csv\", ['HR', 'Temp', 'PTT', 'Platelets', 'WBC', 'Glucose'])\n",
    "df = myloader.load_data_LSTM(100)\n",
    "\n",
    "y_train, y_test, X_train, X_test = myloader.properly_split(df, ['HR'], ['Temp', 'PTT', 'Platelets', 'WBC', 'Glucose'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T14:27:51.836239200Z",
     "start_time": "2025-04-06T14:27:45.717857200Z"
    }
   },
   "id": "c0f94a78ee8de41f"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "                      HR\nPatient_ID ICULOS       \n0          0       117.0\n           1       117.0\n           2       117.0\n           3       117.0\n           4       117.0\n...                  ...\n1          42       85.0\n           43       88.0\n           44       77.0\n           45       84.0\n           46       83.0\n\n[94 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>HR</th>\n    </tr>\n    <tr>\n      <th>Patient_ID</th>\n      <th>ICULOS</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">0</th>\n      <th>0</th>\n      <td>117.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>117.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>117.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>117.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>117.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">1</th>\n      <th>42</th>\n      <td>85.0</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>88.0</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>77.0</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>84.0</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>83.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>94 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T14:19:50.400889200Z",
     "start_time": "2025-04-06T14:19:50.357210500Z"
    }
   },
   "id": "bf35679a27884916"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                      HR\nPatient_ID ICULOS       \n0          47      102.0\n           48      104.0\n           49      104.0\n1          47       83.0\n           48       82.0\n           49       82.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>HR</th>\n    </tr>\n    <tr>\n      <th>Patient_ID</th>\n      <th>ICULOS</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">0</th>\n      <th>47</th>\n      <td>102.0</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>104.0</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>104.0</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">1</th>\n      <th>47</th>\n      <td>83.0</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>82.0</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>82.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T14:20:15.229237400Z",
     "start_time": "2025-04-06T14:20:15.137186800Z"
    }
   },
   "id": "3d36736ff6989142"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "                    Temp   PTT  Platelets   WBC  Glucose\nPatient_ID ICULOS                                       \n0          0       36.00  46.4       64.0   8.9    123.0\n           1       36.00  46.4       64.0   8.9    123.0\n           2       36.00  46.4       64.0   8.9    123.0\n           3       36.00  40.8      114.0   3.9    117.5\n           4       36.00  40.8      114.0   3.9    102.0\n...                  ...   ...        ...   ...      ...\n1          42      36.22  42.8      126.0  11.4    179.0\n           43      36.22  42.8      126.0  11.4    179.0\n           44      36.22  42.8      126.0  11.4    179.0\n           45      36.22  42.8      126.0  11.4    179.0\n           46      36.22  42.8      126.0  11.4    179.0\n\n[94 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Temp</th>\n      <th>PTT</th>\n      <th>Platelets</th>\n      <th>WBC</th>\n      <th>Glucose</th>\n    </tr>\n    <tr>\n      <th>Patient_ID</th>\n      <th>ICULOS</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">0</th>\n      <th>0</th>\n      <td>36.00</td>\n      <td>46.4</td>\n      <td>64.0</td>\n      <td>8.9</td>\n      <td>123.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>36.00</td>\n      <td>46.4</td>\n      <td>64.0</td>\n      <td>8.9</td>\n      <td>123.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>36.00</td>\n      <td>46.4</td>\n      <td>64.0</td>\n      <td>8.9</td>\n      <td>123.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>36.00</td>\n      <td>40.8</td>\n      <td>114.0</td>\n      <td>3.9</td>\n      <td>117.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>36.00</td>\n      <td>40.8</td>\n      <td>114.0</td>\n      <td>3.9</td>\n      <td>102.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th rowspan=\"5\" valign=\"top\">1</th>\n      <th>42</th>\n      <td>36.22</td>\n      <td>42.8</td>\n      <td>126.0</td>\n      <td>11.4</td>\n      <td>179.0</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>36.22</td>\n      <td>42.8</td>\n      <td>126.0</td>\n      <td>11.4</td>\n      <td>179.0</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>36.22</td>\n      <td>42.8</td>\n      <td>126.0</td>\n      <td>11.4</td>\n      <td>179.0</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>36.22</td>\n      <td>42.8</td>\n      <td>126.0</td>\n      <td>11.4</td>\n      <td>179.0</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>36.22</td>\n      <td>42.8</td>\n      <td>126.0</td>\n      <td>11.4</td>\n      <td>179.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>94 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T14:21:33.033796400Z",
     "start_time": "2025-04-06T14:21:32.963295100Z"
    }
   },
   "id": "fb03fab8e391a9f2"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "                    Temp   PTT  Platelets   WBC  Glucose\nPatient_ID ICULOS                                       \n0          47      37.33  32.0       93.0  10.9    111.0\n           48      37.33  32.0       93.0  10.9    123.0\n           49      37.61  32.0       93.0  10.9    123.0\n1          47      36.22  42.8      126.0  11.4    179.0\n           48      37.00  42.8      126.0  11.4    179.0\n           49      37.00  42.8      126.0  11.4    179.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th></th>\n      <th>Temp</th>\n      <th>PTT</th>\n      <th>Platelets</th>\n      <th>WBC</th>\n      <th>Glucose</th>\n    </tr>\n    <tr>\n      <th>Patient_ID</th>\n      <th>ICULOS</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">0</th>\n      <th>47</th>\n      <td>37.33</td>\n      <td>32.0</td>\n      <td>93.0</td>\n      <td>10.9</td>\n      <td>111.0</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>37.33</td>\n      <td>32.0</td>\n      <td>93.0</td>\n      <td>10.9</td>\n      <td>123.0</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>37.61</td>\n      <td>32.0</td>\n      <td>93.0</td>\n      <td>10.9</td>\n      <td>123.0</td>\n    </tr>\n    <tr>\n      <th rowspan=\"3\" valign=\"top\">1</th>\n      <th>47</th>\n      <td>36.22</td>\n      <td>42.8</td>\n      <td>126.0</td>\n      <td>11.4</td>\n      <td>179.0</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>37.00</td>\n      <td>42.8</td>\n      <td>126.0</td>\n      <td>11.4</td>\n      <td>179.0</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>37.00</td>\n      <td>42.8</td>\n      <td>126.0</td>\n      <td>11.4</td>\n      <td>179.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T14:21:34.519585900Z",
     "start_time": "2025-04-06T14:21:34.445445100Z"
    }
   },
   "id": "83faf4c4cc0d6c95"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "HR_LSTM = LSTMmodel2.LSTMforecaster2(['HR'], ['Temp', 'PTT', 'Platelets', 'WBC', 'Glucose'], y_train, y_test, X_train, X_test)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T14:28:06.331981200Z",
     "start_time": "2025-04-06T14:28:06.299857100Z"
    }
   },
   "id": "78f4863c74f5c0e6"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:138: UserWarning: Input size too small. Automatically setting input size to 3 * horizon = 9\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:146: UserWarning: Inference input size too small. Automatically setting inference input size to input_size = 9\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\models\\lstm.py:161: UserWarning: context_size is deprecated and will be removed in future versions.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:535: UserWarning: val_check_steps is greater than max_steps, setting val_check_steps to max_steps.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder | LSTM          | 488 K  | train\n",
      "4 | mlp_decoder  | MLP           | 41.6 K | train\n",
      "-------------------------------------------------------\n",
      "530 K     Trainable params\n",
      "0         Non-trainable params\n",
      "530 K     Total params\n",
      "2.122     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "03f3c9f5ea3242748eaa0b1a10e68934"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e6c8576ddb27497cbb116996d389ed7d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bfef696d693e483e9082143454a102a4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=10` reached.\n"
     ]
    }
   ],
   "source": [
    "HR_LSTM.fit()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T13:48:53.091848Z",
     "start_time": "2025-04-06T13:48:51.870036200Z"
    }
   },
   "id": "dcf10b35909ee5cf"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is fitted. Generating forecasts...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "There are missing combinations of ids and times in `futr_df`.\nYou can run the `make_future_dataframe(df)` method to get the expected combinations or the `get_missing_future(futr_df, df)` method to get the missing combinations.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m LSTMforecasts \u001B[38;5;241m=\u001B[39m \u001B[43mHR_LSTM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\LSTM\\LSTMmodel2.py:33\u001B[0m, in \u001B[0;36mLSTMforecaster2.predict\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     31\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mModel is fitted. Generating forecasts...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 33\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforecaster\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43my_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\forecasting\\base\\_base.py:2487\u001B[0m, in \u001B[0;36m_BaseGlobalForecaster.predict\u001B[1;34m(self, fh, X, y)\u001B[0m\n\u001B[0;32m   2485\u001B[0m \u001B[38;5;66;03m# we call the ordinary _predict if no looping/vectorization needed\u001B[39;00m\n\u001B[0;32m   2486\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_vectorized:\n\u001B[1;32m-> 2487\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfh\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfh\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_inner\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_inner\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2488\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2489\u001B[0m     \u001B[38;5;66;03m# otherwise we call the vectorized version of predict\u001B[39;00m\n\u001B[0;32m   2490\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vectorize(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredict\u001B[39m\u001B[38;5;124m\"\u001B[39m, y\u001B[38;5;241m=\u001B[39my_inner, X\u001B[38;5;241m=\u001B[39mX_inner, fh\u001B[38;5;241m=\u001B[39mfh)\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\forecasting\\base\\adapters\\_neuralforecast.py:504\u001B[0m, in \u001B[0;36m_NeuralForecastAdapter._predict\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m    501\u001B[0m     predict_data[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_col] \u001B[38;5;241m=\u001B[39m y\u001B[38;5;241m.\u001B[39mto_numpy()\u001B[38;5;241m.\u001B[39mflatten()\n\u001B[0;32m    502\u001B[0m     predict_parameters[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdf\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m pandas\u001B[38;5;241m.\u001B[39mDataFrame(data\u001B[38;5;241m=\u001B[39mpredict_data)\n\u001B[1;32m--> 504\u001B[0m model_forecasts \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forecaster\u001B[38;5;241m.\u001B[39mpredict(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpredict_parameters)\n\u001B[0;32m    506\u001B[0m prediction_column_names \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    507\u001B[0m     column\n\u001B[0;32m    508\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m column \u001B[38;5;129;01min\u001B[39;00m model_forecasts\u001B[38;5;241m.\u001B[39mcolumns\n\u001B[0;32m    509\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m column\u001B[38;5;241m.\u001B[39mstartswith(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39malgorithm_name)\n\u001B[0;32m    510\u001B[0m ]\n\u001B[0;32m    512\u001B[0m \u001B[38;5;66;03m# this block is necessary only for specific values of ``loss``\u001B[39;00m\n\u001B[0;32m    513\u001B[0m \u001B[38;5;66;03m# for example, when using ``MQLoss`` for multiple quantiles\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\core.py:932\u001B[0m, in \u001B[0;36mNeuralForecast.predict\u001B[1;34m(self, df, static_df, futr_df, verbose, engine, level, quantiles, **data_kwargs)\u001B[0m\n\u001B[0;32m    930\u001B[0m         expected_cmd \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmake_future_dataframe(df)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    931\u001B[0m         missing_cmd \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mget_missing_future(futr_df, df)\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 932\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    933\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThere are missing combinations of ids and times in `futr_df`.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    934\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mYou can run the `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mexpected_cmd\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` method to get the expected combinations or \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    935\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe `\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmissing_cmd\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m` method to get the missing combinations.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    936\u001B[0m     )\n\u001B[0;32m    937\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m futr_orig_rows \u001B[38;5;241m>\u001B[39m futr_df\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]:\n\u001B[0;32m    938\u001B[0m     dropped_rows \u001B[38;5;241m=\u001B[39m futr_orig_rows \u001B[38;5;241m-\u001B[39m futr_df\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n",
      "\u001B[1;31mValueError\u001B[0m: There are missing combinations of ids and times in `futr_df`.\nYou can run the `make_future_dataframe(df)` method to get the expected combinations or the `get_missing_future(futr_df, df)` method to get the missing combinations."
     ]
    }
   ],
   "source": [
    "LSTMforecasts = HR_LSTM.predict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T13:48:59.531226500Z",
     "start_time": "2025-04-06T13:48:59.414301500Z"
    }
   },
   "id": "563ee9f40692c158"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:138: UserWarning: Input size too small. Automatically setting input size to 3 * horizon = 9\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:146: UserWarning: Inference input size too small. Automatically setting inference input size to input_size = 9\n",
      "  warnings.warn(\n",
      "Seed set to 1\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\models\\lstm.py:161: UserWarning: context_size is deprecated and will be removed in future versions.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emily\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\neuralforecast\\common\\_base_model.py:535: UserWarning: val_check_steps is greater than max_steps, setting val_check_steps to max_steps.\n",
      "  warnings.warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name         | Type          | Params | Mode \n",
      "-------------------------------------------------------\n",
      "0 | loss         | MAE           | 0      | train\n",
      "1 | padder_train | ConstantPad1d | 0      | train\n",
      "2 | scaler       | TemporalNorm  | 0      | train\n",
      "3 | hist_encoder | LSTM          | 488 K  | train\n",
      "4 | mlp_decoder  | MLP           | 41.4 K | train\n",
      "-------------------------------------------------------\n",
      "529 K     Trainable params\n",
      "0         Non-trainable params\n",
      "529 K     Total params\n",
      "2.118     Total estimated model params size (MB)\n",
      "10        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33f61a00fa10433fa0829e8273106d65"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c1c649ea45745d2bdae2689927ae853"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f926dee53b21499abb92a2a1d51f0aff"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=10` reached.\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/plain": "Predicting: |          | 0/? [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "212e3715e1864705a4e774c12d1bc0cb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'[2, 3, 4, 5] not in index'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m LSTMforecasts \u001B[38;5;241m=\u001B[39m \u001B[43mHR_LSTM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\LSTM\\LSTMmodel2.py:36\u001B[0m, in \u001B[0;36mLSTMforecaster2.fit_predict\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mfit_predict\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m     35\u001B[0m     fh \u001B[38;5;241m=\u001B[39m ForecastingHorizon([\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m])\n\u001B[1;32m---> 36\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforecaster\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfh\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfh\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX_pred\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\forecasting\\base\\_base.py:544\u001B[0m, in \u001B[0;36mBaseForecaster.fit_predict\u001B[1;34m(self, y, X, fh, X_pred)\u001B[0m\n\u001B[0;32m    542\u001B[0m \u001B[38;5;66;03m# if X_pred is passed, run fit/predict with different X\u001B[39;00m\n\u001B[0;32m    543\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m X_pred \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 544\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfh\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfh\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_pred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    545\u001B[0m \u001B[38;5;66;03m# otherwise, we use the same X for fit and predict\u001B[39;00m\n\u001B[0;32m    546\u001B[0m \u001B[38;5;66;03m# below code carries out conversion and checks for X only once\u001B[39;00m\n\u001B[0;32m    547\u001B[0m \n\u001B[0;32m    548\u001B[0m \u001B[38;5;66;03m# if fit is called, fitted state is re-set\u001B[39;00m\n\u001B[0;32m    549\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_fitted \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\forecasting\\base\\_base.py:2487\u001B[0m, in \u001B[0;36m_BaseGlobalForecaster.predict\u001B[1;34m(self, fh, X, y)\u001B[0m\n\u001B[0;32m   2485\u001B[0m \u001B[38;5;66;03m# we call the ordinary _predict if no looping/vectorization needed\u001B[39;00m\n\u001B[0;32m   2486\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_vectorized:\n\u001B[1;32m-> 2487\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfh\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfh\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX_inner\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my_inner\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2488\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2489\u001B[0m     \u001B[38;5;66;03m# otherwise we call the vectorized version of predict\u001B[39;00m\n\u001B[0;32m   2490\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_vectorize(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpredict\u001B[39m\u001B[38;5;124m\"\u001B[39m, y\u001B[38;5;241m=\u001B[39my_inner, X\u001B[38;5;241m=\u001B[39mX_inner, fh\u001B[38;5;241m=\u001B[39mfh)\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\sktime\\forecasting\\base\\adapters\\_neuralforecast.py:533\u001B[0m, in \u001B[0;36m_NeuralForecastAdapter._predict\u001B[1;34m(***failed resolving arguments***)\u001B[0m\n\u001B[0;32m    528\u001B[0m id_ins \u001B[38;5;241m=\u001B[39m pandas\u001B[38;5;241m.\u001B[39mDataFrame(\n\u001B[0;32m    529\u001B[0m     data\u001B[38;5;241m=\u001B[39mins, index\u001B[38;5;241m=\u001B[39mid_int, columns\u001B[38;5;241m=\u001B[39mnew_index_names[:\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m    530\u001B[0m )\n\u001B[0;32m    531\u001B[0m id_ins \u001B[38;5;241m=\u001B[39m id_ins\u001B[38;5;241m.\u001B[39mdrop_duplicates()\n\u001B[0;32m    532\u001B[0m final_predictions \u001B[38;5;241m=\u001B[39m pandas\u001B[38;5;241m.\u001B[39mconcat(\n\u001B[1;32m--> 533\u001B[0m     (model_forecasts, \u001B[43mid_ins\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mloc\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmodel_forecasts\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtolist\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m),\n\u001B[0;32m    534\u001B[0m     axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[0;32m    535\u001B[0m )\n\u001B[0;32m    536\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_is_PeriodIndex:\n\u001B[0;32m    537\u001B[0m     time_idx \u001B[38;5;241m=\u001B[39m pandas\u001B[38;5;241m.\u001B[39mDatetimeIndex(final_predictions[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtime_col])\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\pandas\\core\\indexing.py:1191\u001B[0m, in \u001B[0;36m_LocationIndexer.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1189\u001B[0m maybe_callable \u001B[38;5;241m=\u001B[39m com\u001B[38;5;241m.\u001B[39mapply_if_callable(key, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj)\n\u001B[0;32m   1190\u001B[0m maybe_callable \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_deprecated_callable_usage(key, maybe_callable)\n\u001B[1;32m-> 1191\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmaybe_callable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\pandas\\core\\indexing.py:1420\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_axis\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1417\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(key, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mndim\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m key\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   1418\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot index with multidimensional key\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m-> 1420\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem_iterable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1422\u001B[0m \u001B[38;5;66;03m# nested tuple slicing\u001B[39;00m\n\u001B[0;32m   1423\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_nested_tuple(key, labels):\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\pandas\\core\\indexing.py:1360\u001B[0m, in \u001B[0;36m_LocIndexer._getitem_iterable\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1357\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_key(key, axis)\n\u001B[0;32m   1359\u001B[0m \u001B[38;5;66;03m# A collection of keys\u001B[39;00m\n\u001B[1;32m-> 1360\u001B[0m keyarr, indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_listlike_indexer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1361\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_reindex_with_indexers(\n\u001B[0;32m   1362\u001B[0m     {axis: [keyarr, indexer]}, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, allow_dups\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m   1363\u001B[0m )\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\pandas\\core\\indexing.py:1558\u001B[0m, in \u001B[0;36m_LocIndexer._get_listlike_indexer\u001B[1;34m(self, key, axis)\u001B[0m\n\u001B[0;32m   1555\u001B[0m ax \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis(axis)\n\u001B[0;32m   1556\u001B[0m axis_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mobj\u001B[38;5;241m.\u001B[39m_get_axis_name(axis)\n\u001B[1;32m-> 1558\u001B[0m keyarr, indexer \u001B[38;5;241m=\u001B[39m \u001B[43max\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1560\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m keyarr, indexer\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[1;34m(self, key, axis_name)\u001B[0m\n\u001B[0;32m   6197\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6198\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[1;32m-> 6200\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6202\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[0;32m   6203\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[0;32m   6204\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[1;32m~\\Documents\\DissertationProject\\venv_python\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[1;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[0;32m   6249\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   6251\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[1;32m-> 6252\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mKeyError\u001B[0m: '[2, 3, 4, 5] not in index'"
     ]
    }
   ],
   "source": [
    "LSTMforecasts = HR_LSTM.fit_predict()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T14:28:22.102390500Z",
     "start_time": "2025-04-06T14:28:15.407357300Z"
    }
   },
   "id": "a4f07bb38391c89a"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6d5be32a25d94d9d"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# importing necessary libraries\n",
    "from sktime.datasets import load_longley\n",
    "from sktime.forecasting.neuralforecast import NeuralForecastLSTM\n",
    "from sktime.split import temporal_train_test_split\n",
    "\n",
    "# loading the Longley dataset and splitting it into train and test subsets\n",
    "y, X = load_longley()\n",
    "y_train, y_test, X_train, X_test = temporal_train_test_split(y, X, test_size=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T14:15:40.578686600Z",
     "start_time": "2025-04-06T14:15:40.494537700Z"
    }
   },
   "id": "21e97fec55aab71f"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "Period\n1947    60323.0\n1948    61122.0\n1949    60171.0\n1950    61187.0\n1951    63221.0\n1952    63639.0\n1953    64989.0\n1954    63761.0\n1955    66019.0\n1956    67857.0\n1957    68169.0\n1958    66513.0\nFreq: Y-DEC, Name: TOTEMP, dtype: float64"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T14:15:55.533037600Z",
     "start_time": "2025-04-06T14:15:55.485393Z"
    }
   },
   "id": "7f0f442349f4fbd0"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Period\n1959    68655.0\n1960    69564.0\n1961    69331.0\n1962    70551.0\nFreq: Y-DEC, Name: TOTEMP, dtype: float64"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T14:16:09.457571Z",
     "start_time": "2025-04-06T14:16:09.407442500Z"
    }
   },
   "id": "1513224fea7cc9b8"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "        GNPDEFL       GNP   UNEMP   ARMED       POP\nPeriod                                             \n1947       83.0  234289.0  2356.0  1590.0  107608.0\n1948       88.5  259426.0  2325.0  1456.0  108632.0\n1949       88.2  258054.0  3682.0  1616.0  109773.0\n1950       89.5  284599.0  3351.0  1650.0  110929.0\n1951       96.2  328975.0  2099.0  3099.0  112075.0\n1952       98.1  346999.0  1932.0  3594.0  113270.0\n1953       99.0  365385.0  1870.0  3547.0  115094.0\n1954      100.0  363112.0  3578.0  3350.0  116219.0\n1955      101.2  397469.0  2904.0  3048.0  117388.0\n1956      104.6  419180.0  2822.0  2857.0  118734.0\n1957      108.4  442769.0  2936.0  2798.0  120445.0\n1958      110.8  444546.0  4681.0  2637.0  121950.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GNPDEFL</th>\n      <th>GNP</th>\n      <th>UNEMP</th>\n      <th>ARMED</th>\n      <th>POP</th>\n    </tr>\n    <tr>\n      <th>Period</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1947</th>\n      <td>83.0</td>\n      <td>234289.0</td>\n      <td>2356.0</td>\n      <td>1590.0</td>\n      <td>107608.0</td>\n    </tr>\n    <tr>\n      <th>1948</th>\n      <td>88.5</td>\n      <td>259426.0</td>\n      <td>2325.0</td>\n      <td>1456.0</td>\n      <td>108632.0</td>\n    </tr>\n    <tr>\n      <th>1949</th>\n      <td>88.2</td>\n      <td>258054.0</td>\n      <td>3682.0</td>\n      <td>1616.0</td>\n      <td>109773.0</td>\n    </tr>\n    <tr>\n      <th>1950</th>\n      <td>89.5</td>\n      <td>284599.0</td>\n      <td>3351.0</td>\n      <td>1650.0</td>\n      <td>110929.0</td>\n    </tr>\n    <tr>\n      <th>1951</th>\n      <td>96.2</td>\n      <td>328975.0</td>\n      <td>2099.0</td>\n      <td>3099.0</td>\n      <td>112075.0</td>\n    </tr>\n    <tr>\n      <th>1952</th>\n      <td>98.1</td>\n      <td>346999.0</td>\n      <td>1932.0</td>\n      <td>3594.0</td>\n      <td>113270.0</td>\n    </tr>\n    <tr>\n      <th>1953</th>\n      <td>99.0</td>\n      <td>365385.0</td>\n      <td>1870.0</td>\n      <td>3547.0</td>\n      <td>115094.0</td>\n    </tr>\n    <tr>\n      <th>1954</th>\n      <td>100.0</td>\n      <td>363112.0</td>\n      <td>3578.0</td>\n      <td>3350.0</td>\n      <td>116219.0</td>\n    </tr>\n    <tr>\n      <th>1955</th>\n      <td>101.2</td>\n      <td>397469.0</td>\n      <td>2904.0</td>\n      <td>3048.0</td>\n      <td>117388.0</td>\n    </tr>\n    <tr>\n      <th>1956</th>\n      <td>104.6</td>\n      <td>419180.0</td>\n      <td>2822.0</td>\n      <td>2857.0</td>\n      <td>118734.0</td>\n    </tr>\n    <tr>\n      <th>1957</th>\n      <td>108.4</td>\n      <td>442769.0</td>\n      <td>2936.0</td>\n      <td>2798.0</td>\n      <td>120445.0</td>\n    </tr>\n    <tr>\n      <th>1958</th>\n      <td>110.8</td>\n      <td>444546.0</td>\n      <td>4681.0</td>\n      <td>2637.0</td>\n      <td>121950.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T14:17:13.821277700Z",
     "start_time": "2025-04-06T14:17:13.710096100Z"
    }
   },
   "id": "ef13bb43a5de28d6"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "        GNPDEFL       GNP   UNEMP   ARMED       POP\nPeriod                                             \n1959      112.6  482704.0  3813.0  2552.0  123366.0\n1960      114.2  502601.0  3931.0  2514.0  125368.0\n1961      115.7  518173.0  4806.0  2572.0  127852.0\n1962      116.9  554894.0  4007.0  2827.0  130081.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>GNPDEFL</th>\n      <th>GNP</th>\n      <th>UNEMP</th>\n      <th>ARMED</th>\n      <th>POP</th>\n    </tr>\n    <tr>\n      <th>Period</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1959</th>\n      <td>112.6</td>\n      <td>482704.0</td>\n      <td>3813.0</td>\n      <td>2552.0</td>\n      <td>123366.0</td>\n    </tr>\n    <tr>\n      <th>1960</th>\n      <td>114.2</td>\n      <td>502601.0</td>\n      <td>3931.0</td>\n      <td>2514.0</td>\n      <td>125368.0</td>\n    </tr>\n    <tr>\n      <th>1961</th>\n      <td>115.7</td>\n      <td>518173.0</td>\n      <td>4806.0</td>\n      <td>2572.0</td>\n      <td>127852.0</td>\n    </tr>\n    <tr>\n      <th>1962</th>\n      <td>116.9</td>\n      <td>554894.0</td>\n      <td>4007.0</td>\n      <td>2827.0</td>\n      <td>130081.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-04-06T14:17:30.489189100Z",
     "start_time": "2025-04-06T14:17:30.434460Z"
    }
   },
   "id": "40f4a5c6dd959cd8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "7904107e2cc180b9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
